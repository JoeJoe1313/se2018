% arara: pdflatex: { shell: true, interaction: nonstopmode }
% arara: biber
% arara: pdflatex: { shell: true }

\documentclass[numbers=endperiod, DIV=15, bibliography=totocnumbered]{scrartcl}

% Base packages
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}
\usepackage[pdfencoding=unicode]{hyperref}
\usepackage{biblatex}
\usepackage[style=german]{csquotes}

% Base math packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}

% Custom packages
\usepackage{../../common/macros}
\usepackage{../../common/theorems}

% Misc packages
\usepackage{ulem} % Line-breaking underlines

% Bibliography
\addbibresource{./references.bib}

% Document
\title{Тема 19}
\subtitle{Проверка на хипотези.}
\author{Янис Василев, \Email{ianis@ivasilev.net}}
\date{28 юни 2019}

\begin{document}

\maketitle

\section{Теория}

Теорията е базирана на~\cite{DimitrovYanev}.

\subsection{Анотация}

Изложената анотацията е взета от конспекта~\cite{Syllabus} за 2018г.

\begin{enumerate}
  \item Определение за статистичека хипотеза
  \item Прости и сложни хипотези
  \item Определения за грешки от първи и твори род, критична област, мощност, значимост на тест и значимост на статистиката на теста
  \item Лема на Нейман–Пирсън
\end{enumerate}

\subsection{Основни понятия}

Считаме, че е зададено вероятностно пространство $(\Omega, \F, \Prob)$. Под \uline{плътност} $f_\xi(x)$ на случайната величина $\xi$ ще разбираме обикновената плътност при непрекъснати и функцията на вероятностите при дискретни случайни величини.

\begin{definition}[Извадки]
  Нека $\xi$ е случайна величина над $(\Omega, \F, \Prob)$. Множеството от елементарни събития $\Omega$ в статистиката често се нарича \uline{генерална съвкупност}

  \begin{itemize}
    \item Ако случайните величини $\xi_1, \ldots, \xi_n$ са независими две по две и имат същото разпределение като $\xi$, казваме, че $\xi_1, \ldots, \xi_n$ са \uline{наблюдения над $\xi$} и че те са \uline{проста извадка с обем $n$} над генералната съвкупност $\Omega$.
    \item Съвместната плътност $L(x_1, \ldots, x_n)$ на една извадка наричаме \uline{функция на правдоподобие на извадката}. При извадки от независими случайни величини, функцията на правдоподобие е просто произведение на съответните плътности.
    \item \uline{Извадково} пространство, съответстващо на извадката $\xi_1, \ldots, \xi_n$, наричаме множеството $\SampleSpace \subseteq \R^n$ от стойности на случайния вектор $(\xi_1, \ldots, \xi_n)$.
    \item \uline{Реализации} на извадката наричаме вектори от $\SampleSpace$. Те моделират истинските данни в математическата статистика, съпоставяйки ги на~\enquote{теоретичната} извадка $(\xi_1, \ldots, \xi_n)$.
  \end{itemize}
\end{definition}

\begin{definition}[Хипотези]
  Нека $\xi_1, \ldots \xi_n$ са наблюдения над $\xi$, чието разпределение не ни е известно.

  \begin{itemize}
    \item Всяко предположение за разпределението на $\xi$ наричаме \uline{статистическа хипотеза}. Формално, хипотезата $H$ често се представя като множество от възможни функции на разпределение на $\xi$. При повече от една хипотеза, искаме те да не се пресичат. Условна вероятност при условие, че $F_\xi \in H$, обикновена записваме чрез
    \begin{displaymath}
      \Prob(\cdot \mid H).
    \end{displaymath}

    Обикновено се разглеждат само две хипотези: \uline{нулевата хипотеза $H_0$} и \uline{алтернативната хипотеза $H_1$}.

    \item При \uline{параметричната} статистика хипотезите се отнасят за параметри на семейства от разпределения, например за очакването $\mu$ на нормално разпределение или степента $\lambda$ на Поасоново разпределение. В противен случай говорим за \uline{непараметрична} статистика.

    \item За да направим заключение за верността на една хипотеза ни е необходим \uline{статистически критерий}. Формално, статистическите критерии са изображения $\delta: \SampleSpace \to \{ H_0, H_1 \}$, съпоставящи на реализация на извадка някоя хипотеза. Да отбележим, че критерият $\delta$ сам по себе си е случайна величина.

    \item Един критерий ни казва коя хипотеза да \uline{приемем} и коя да \uline{отхвърлим}, обикновено на базата на данни от експеримент, т.е. на някоя реализация на извадка над $\xi$. Поради случайния характер на експериментите, обаче, при практически задачи е възприета терминологията \uline{имаме/нямаме основание да отхвърлим хипотезата $H$ на база на данните} или \uline{хипотезата $H$ е/не е съвместима с данните}.

    \item \uline{Статистически тест} наричаме набор от хипотези и съгласуван с тях критерии.

    \item \uline{Вероятността $\alpha$ за грешка от първи род} или \uline{ниво на съгласие} или \uline{ниво на значимост} е вероятността да отхвърлим вярна нулева хипотеза, т.е.
    \begin{displaymath}
      \alpha \coloneqq \Prob(\delta = H_1 \mid H_0).
    \end{displaymath}

    Стойността $\gamma \coloneqq 1 - \alpha$ наричаме \uline{значимост} или \uline{ниво на доверие} на теста.

    \item \uline{Вероятността $\beta$ за грешка от втори род} е вероятността да приемем грешна нулева хипотеза, т.е.
    \begin{displaymath}
      \beta \coloneqq \Prob(\delta = H_0 \mid H_1).
    \end{displaymath}

    Стойността $\pi \coloneqq 1 - \beta$ наричаме \uline{мощност} на теста.

    \item \uline{Критична област} $W_\alpha$ с ниво на значимост $\alpha$ наричаме произволно множество $W_\alpha \subsetneq \SampleSpace$ от реализации на извадката с $\Prob(W \mid H_0) = \alpha$, попадайки в което \uline{отхвърляме} нулевата хипотеза.

    Всяка критична област задава критерия
    \begin{displaymath}
      \delta(x) = \begin{cases}
        H_1, x \in W, \\
        H_0, x \not\in W.
      \end{cases}
    \end{displaymath}

    \item Нека са зададени хипотезите $H_0$ и $H_1$ и е фиксирано ниво на значимост $\alpha$. Критичната област
    \begin{displaymath}
      W_\alpha^* \coloneqq \Argmax_{W_\alpha \subsetneq \SampleSpace} \Prob(\SampleSpace \setminus W_\alpha \mid H_1),
    \end{displaymath}
    осигуряваща най-голяма мощност на теста, наричаме~\uline{оптимална критична област}.

    \item Хипотезата наричаме \uline{проста}, ако на нея отговаря точно едно разпределение. В противен случая я наричаме \uline{сложна}. Ако имаме една проста хипотеза и една сложна, избираме нулевата да бъде проста. Така имаме три случая:
    \begin{enumerate}
      \item Проста хипотеза срещу проста алтернатива,
      \item Проста хипотеза срещу сложна алтернатива,
      \item Сложна хипотеза срещу сложна алтернатива.
    \end{enumerate}

    \item Нека $H_0$ е проста хипотеза и $x = (x_1, \ldots, x_n) \in \SampleSpace$ е реализация на извадка. \uline{Значимост или $p$-стойност на реализацията} $x$ наричаме условната вероятност спрямо нулева хипотеза $H_0$ на опашките на разпределението на $\xi$, определени от типа на теста.

    В зависимост от типа на теста разполагаме с няколко формални определения за значимост на реализация:
    \begin{displaymath}
      p \coloneqq \begin{cases}
        \Prob(x \leq \xi \mid H_0), &\text{ за леви едностранни тестове} \\
        \Prob(x \geq \xi \mid H_0), &\text{ за десни едностранни тестове} \\
        2 \min (\Prob(x \leq \xi \mid H_0), \Prob(x \geq \xi \mid H_0)) &\text{ за двустранни тестове}
      \end{cases}
    \end{displaymath}

    Често се казва, че значимостта на $x$ е вероятността да наблюдаваме~\enquote{по-екстремна} стойност от $x$.
  \end{itemize}
\end{definition}

\subsection{Лема на Нейман-Пирсън}

\begin{lemma}[Нейман-Пирсън]
  Нека са дадени две прости хипотеза за функцията на правдоподобие на извадка $\xi_1, \ldots, \xi_n$ над случайна величина $\xi$,
  \begin{displaymath}
    \begin{cases}
      H_0: &L(x) = L_0(x) \\
      H_1: &L(x) = L_1(x).
    \end{cases}
  \end{displaymath}

  Считаме, че е зададено ниво на съгласие $\alpha$. Ако за някоя константа $c \in \R$ критичната област $W_\alpha$ има вида
  \begin{displaymath}
    W_\alpha = \{ x \in \SampleSpace \mid L_0(x) \leq c L_1(x) \},
  \end{displaymath}
  тогава $W_\alpha$ е оптимална критична област.
\end{lemma}

\printbibliography

\end{document}
