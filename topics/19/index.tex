% arara: pdflatex: { shell: true, interaction: nonstopmode }
% arara: biber
% arara: pdflatex: { shell: true }

\documentclass[numbers=endperiod, DIV=15, bibliography=totocnumbered]{scrartcl}

% Base packages
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}
\usepackage[pdfencoding=unicode]{hyperref}
\usepackage{biblatex}
\usepackage[style=german]{csquotes}

% Base math packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}

% Custom packages
\usepackage{../../common/macros}
\usepackage{../../common/theorems}

% Misc packages
\usepackage{ulem} % Line-breaking underlines

% Bibliography
\addbibresource{./references.bib}

% Document
\title{Тема 19}
\subtitle{Проверка на хипотези.}
\author{Янис Василев, \Email{ianis@ivasilev.net}}
\date{28 юни 2019}

\begin{document}

\maketitle

\section{Теория}

Лемата на Нейман-Пирсън е базирана на изложението ѝ в~\cite{DimitrovYanev}.

\subsection{Анотация}

Изложената анотацията е взета от конспекта~\cite{Syllabus} за 2018г.

\begin{enumerate}
  \item Определение за статистичека хипотеза
  \item Прости и сложни хипотези
  \item Определения за грешки от първи и твори род, критична област, мощност, значимост на тест и значимост на статистиката на теста
  \item Лема на Нейман–Пирсън
\end{enumerate}

\subsection{Основни понятия}

Считаме, че е зададено вероятностно пространство $(\Omega, \F, \Prob)$.

\begin{definition}[Извадки]
  Нека $\xi$ е случайна величина над $(\Omega, \F, \Prob)$. Множеството от елементарни събития $\Omega$ в статистиката често се нарича \uline{генерална съвкупност}.

  \begin{itemize}
    \item Ако случайните величини $\xi_1, \ldots, \xi_n$ са независими две по две и имат същото разпределение като $\xi$, казваме, че $\xi_1, \ldots, \xi_n$ са \uline{наблюдения над $\xi$} и че те са \uline{проста извадка с обем $n$} над генералната съвкупност $\Omega$. Понякога ги разглеждаме и като случаен вектор $\V{\xi_n} = (\xi_1, \ldots, \xi_n)$.
    \item \uline{Функция на правдоподобие $l_\xi(x)$} на случайната величина $\xi$ наричаме, в абсолютно непрекъснатия случай, плътността на $\xi$ или, в дискретния случай, функцията на вероятностите на $\xi$.
    \item \uline{Функция на правдоподобие $l(x_1, \ldots, x_n)$ на извадката $\xi_1, \ldots, \xi_n$} наричаме функцията на правдоподобие на случайния вектор $\V{\xi_n}$. При извадки от независими случайни величини, функцията на правдоподобие на извадката е произведение на индивидуалните функции на правдоподобие.
    \item \uline{Извадково} пространство, съответстващо на извадката $\xi_1, \ldots, \xi_n$, наричаме множеството $\SampleSpace \subseteq \R^n$ от стойности на случайния вектор $\V{\xi_n}$.
    \item \uline{Реализации} на извадката наричаме вектори от $\SampleSpace$. Те моделират истинските данни в математическата статистика, съпоставяйки ги на~\enquote{теоретичната} извадка $\xi_1, \ldots, \xi_n$.
  \end{itemize}
\end{definition}

\begin{definition}[Хипотези]
  Нека $\xi_1, \ldots \xi_n$ е проста извадка над случайната величина $\xi$, чието разпределение не ни е известно.

  \begin{itemize}
    \item Всяко предположение за разпределението на $\xi$ наричаме \uline{статистическа хипотеза}. Формално, хипотезата $H$ често се представя като множество от възможни функции на разпределение на $\xi$. При повече от една хипотеза, искаме те да не се пресичат. Условна вероятност при условие, че $F_\xi \in H$, обикновена записваме чрез
    \begin{displaymath}
      \Prob(\cdot \mid H).
    \end{displaymath}

    Обикновено се разглеждат само две хипотези: \uline{нулевата хипотеза $H_0$} и \uline{алтернативната хипотеза $H_1$}.

    \item При \uline{параметричната} статистика хипотезите се отнасят за параметри на семейства от разпределения, например за очакването $\mu$ на нормално разпределение или степента $\lambda$ на Поасоново разпределение. В противен случай говорим за \uline{непараметрична} статистика. В непараметричния случай считаме, че двете хипотези съдържат едновременно само дискретни или само непрекъснати разпределения.

    \item За да направим заключение за верността на една хипотеза ни е необходим \uline{статистически критерий}. Формално, статистическите критерии са изображения $\delta: \SampleSpace \to \{ H_0, H_1 \}$, съпоставящи на реализация на извадка някоя хипотеза. Да отбележим, че критерият $\delta$ сам по себе си е случайна величина.

    \item Един критерий ни казва коя хипотеза да \uline{приемем} и коя да \uline{отхвърлим}, обикновено на базата на данни от експеримент, т.е. на някоя реализация на извадка над $\xi$. Поради случайния характер на експериментите, обаче, при практически задачи е възприета терминологията \uline{имаме/нямаме основание да отхвърлим хипотезата $H$ на база на данните} или \uline{хипотезата $H$ е/не е съвместима с данните}.

    \item \uline{Статистически тест} наричаме набор от хипотези и съгласуван с тях критерии.

    \item \uline{Вероятността $\alpha$ за грешка от първи род} или \uline{ниво на съгласие} или \uline{ниво на значимост} е вероятността да отхвърлим вярна нулева хипотеза, т.е.
    \begin{displaymath}
      \alpha \coloneqq \Prob(\delta = H_1 \mid H_0).
    \end{displaymath}

    Стойността $\gamma \coloneqq 1 - \alpha$ наричаме \uline{значимост} или \uline{ниво на доверие} на теста.

    \item \uline{Вероятността $\beta$ за грешка от втори род} е вероятността да приемем грешна нулева хипотеза, т.е.
    \begin{displaymath}
      \beta \coloneqq \Prob(\delta = H_0 \mid H_1).
    \end{displaymath}

    Стойността $\pi \coloneqq 1 - \beta$ наричаме \uline{мощност} на теста.

    \item \uline{Критична област} $W_\alpha$ с ниво на значимост $\alpha$ наричаме произволно множество $W_\alpha \subsetneq \SampleSpace$ от реализации на извадката с $\Prob(\V{\xi_n} \in W \mid H_0) = \alpha$, попадайки в което \uline{отхвърляме} нулевата хипотеза.

    Всяка критична област задава критерия
    \begin{displaymath}
      \delta(x) = \begin{cases}
        H_1, x \in W, \\
        H_0, x \not\in W.
      \end{cases}
    \end{displaymath}

    \item Нека са зададени хипотезите $H_0$ и $H_1$ и е фиксирано ниво на значимост $\alpha$. Критичната област
    \begin{displaymath}
      W_\alpha^* \coloneqq \Argmax_{W_\alpha \subsetneq \SampleSpace} \Prob(\V{\xi_n} \in W_\alpha \mid H_1),
    \end{displaymath}
    осигуряваща най-голяма мощност на теста, наричаме~\uline{оптимална критична област}.

    \item Хипотезата наричаме \uline{проста}, ако на нея отговаря точно едно разпределение. В противен случая я наричаме \uline{сложна}. Ако имаме една проста хипотеза и една сложна, избираме нулевата да бъде проста. Така имаме три случая:
    \begin{enumerate}
      \item Проста хипотеза срещу проста алтернатива,
      \item Проста хипотеза срещу сложна алтернатива,
      \item Сложна хипотеза срещу сложна алтернатива.
    \end{enumerate}

    \item Разглеждаме тест с две хипотези $H_0$ и $H_1$ като множества от възможни функции на разпределение на $\xi$. Имаме три случая
    \begin{itemize}
      \item Ако $F_1(x) \leq F_0(x)~\forall F_0 \in H_0, F_1 \in H_1$, наричаме теста \uline{ляв едностранен}
      \item Ако $F_1(x) \geq F_0(x)~\forall F_0 \in H_0, F_1 \in H_1$, наричаме теста \uline{десен едностранен}
      \item В противен случай, наричаме теста \uline{двустранен}
    \end{itemize}

    \item Нека $H_0$ е проста хипотеза и $x = (x_1, \ldots, x_n) \in \SampleSpace$ е реализация на извадка. \uline{Значимост или $p$-стойност на реализацията} $x$ наричаме условната вероятност спрямо нулева хипотеза $H_0$ на опашките на разпределението на $\xi$, определени от типа на теста.

    В зависимост от типа на теста разполагаме с няколко формални определения за значимост на реализация:
    \begin{displaymath}
      p \coloneqq \begin{cases}
        \Prob(x \leq \xi \mid H_0), &\text{ за леви едностранни тестове} \\
        \Prob(x \geq \xi \mid H_0), &\text{ за десни едностранни тестове} \\
        2 \min (\Prob(x \leq \xi \mid H_0), \Prob(x \geq \xi \mid H_0)) &\text{ за двустранни тестове}
      \end{cases}
    \end{displaymath}

    Често се казва, че значимостта на $x$ е вероятността да наблюдаваме~\enquote{по-екстремна} стойност от $x$.
  \end{itemize}
\end{definition}

\subsection{Лема на Нейман-Пирсън}

\begin{lemma}[Нейман-Пирсън]
  Нека са дадени две прости хипотези за функцията на правдоподобие на извадка $\xi_1, \ldots, \xi_n$ над случайна величина $\xi$,
  \begin{displaymath}
    \begin{cases}
      H_0: &l(x) = l_0(x) \\
      H_1: &l(x) = l_1(x).
    \end{cases}
  \end{displaymath}

  Считаме, че е зададено ниво на съгласие $\alpha$. Ако за някоя реална константа $c > 0$ за критичната област $W_\alpha$ са изпълнени неравенствата
  \begin{align*}
    &l_0(x) \leq c \cdot l_1(x), x \in W_\alpha, \\
    &l_0(x) \geq c \cdot l_1(x), x \not\in W_\alpha,
  \end{align*}
  тогава $W_\alpha$ е оптимална критична област.
\end{lemma}

\begin{note}
  В общия случай стойностите $x \in \SampleSpace$, за които $l_0(x) = cl_1(x)$, могат както да лежат в критичната област, така и извън нея.
\end{note}

\begin{proof}
  Ще докажем теоремата само за абсолютно непрекъснати разпределения. В общия случай римановите интеграли могат да се заменят с интеграли по вероятностни мерки, съответстващи на двете хипотези.

  Нека $U_\alpha$ е произволна друга критична област за същия тест с ниво на съгласие $\alpha$. Означаваме $Q(A) \coloneqq \Prob(\V{\xi_n} \in A)$.

   Ще докажем, че $Q(U_\alpha \mid H_1) \geq Q(W_\alpha \mid H_1)$. Поради адитивността на вероятностните мерки имаме
  \begin{align*}
    &\hspace{0.45cm}Q(W_\alpha \mid H_1) - Q(U_\alpha \mid H_1)
    = \\ &=
    Q((U_\alpha \cap W_\alpha) \cup (W_\alpha \setminus U_\alpha) \mid H_1) - Q((U_\alpha \cap W_\alpha) \cup (U_\alpha \setminus W_\alpha) \mid H_1)
    = \\ &=
    Q(U_\alpha \cap W_\alpha \mid H_1) + Q(W_\alpha \setminus U_\alpha \mid H_1) - Q(U_\alpha \cap W_\alpha \mid H_1) - Q(U_\alpha \setminus W_\alpha \mid H_1)
    = \\ &=
    Q(W_\alpha \setminus U_\alpha \mid H_1) - Q(U_\alpha \setminus W_\alpha \mid H_1)
    = \\ &=
    \int_{W_\alpha \setminus U_\alpha} l_1(x) dx + \int_{U_\alpha \setminus W_\alpha} (-l_1(x)) dx
    \geq \\ &\geq
    \frac 1 c \int_{W_\alpha \setminus U_\alpha} l_0(x) dx + \frac 1 c \int_{U_\alpha \setminus W_\alpha} (-l_0(x)) dx
    = \\ &=
    \frac 1 c \left( \int_{W_\alpha \setminus U_\alpha} l_0(x) dx - \int_{U_\alpha \setminus W_\alpha} l_0(x) dx \right)
    = \\ &=
    \frac 1 c [Q(W_\alpha \setminus U_\alpha \mid H_0) - Q(U_\alpha \setminus W_\alpha \mid H_0)]
    = \\ &=
    \frac 1 c [Q(U_\alpha \cap W_\alpha \mid H_0) + Q(W_\alpha \setminus U_\alpha \mid H_0) - Q(U_\alpha \cap W_\alpha \mid H_0) - Q(U_\alpha \setminus W_\alpha \mid H_0)]
    = \\ &=
    \frac 1 c [Q(W_\alpha \mid H_0) - Q(U_\alpha \mid H_0)]
    = \\ &=
    \frac 1 c (\alpha - \alpha)
    =
    0.
  \end{align*}
\end{proof}

\printbibliography

\end{document}
