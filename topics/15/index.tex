% arara: pdflatex: { shell: true, interaction: nonstopmode }
% arara: biber
% arara: pdflatex: { shell: true }

\documentclass[numbers=endperiod, DIV=15, bibliography=totocnumbered]{scrartcl}

% Base packages
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}
\usepackage[pdfencoding=unicode]{hyperref}
\usepackage{biblatex}
\usepackage[style=german]{csquotes}

% Base math packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}

% Custom packages
\usepackage{../../common/macros}
\usepackage{../../common/theorems}

% Bibliography
\addbibresource{./references.bib}

% Document
\title{Тема 15}
\subtitle{Случайни величини с дискретни разпределения - дискретно равномерно, биномно, геометрично, поасоново разпределения. Задачи, в които възникват.}
\author{Янис Василев, \Email{ianis@ivasilev.net}}
\date{18 юни 2019}

\begin{document}

\maketitle

\section{Анотация}

Изложената анотацията е взета от конспекта~\cite{Syllabus} за 2018г.

\subsection{Теория}

\begin{enumerate}
  \item Дефиниция на дискретно разпределение на случайна величина
  \item Неотрицателност и нормираност на вероятностите на дискретна случайна величина
  \item Дефиниция на моментите на дискретна случайна величина
  \item Дефиниция и свойства (без доказателства) на пораждаща/пораждаща моментите/характеристична функция (по избор)
  \item Дефиниция, коректност, мотивиращ пример, пораждаща/пораждаща моментите/характеристична функция, очакване и дисперсия за две избрани от комисията дискретни разпределения
\end{enumerate}

\subsection{Задачи}

Не е даден списък с възможни задачи, затова съм включил разни задачи, давани на държавен изпит.

\section{Теория}

Теорията е представена с минимални препратки към теорията на мярката и е базирана частично на изложението в~\cite{Borovkov} и~\cite{DimitrovYanev}. За пълнота съм включил доказателства на основните свойства на пораждащи, пораждащи моментите и характеристична функции. За да се запази простотата на изложението, не са включени понятия като функция на разпределение и функция на вероятностите.

\subsection{Основни дефиниции и теореми}

\begin{definition}
  \underline{(Реална) случайна величина} над вероятностното пространство $(\Omega, \F, \Prob)$ наричаме всяка измерима функция $\xi : \Omega \to \R$.

  Условието за измеримост на $\xi$ може да се запише така: за всяко борелово множество $B \in \BorelAlgebra(\R)$ имаме
  \begin{displaymath}
    \xi^{-1} (B) = \{ \omega \in \Omega \mid \xi(\omega) \in B \} \in \F.
  \end{displaymath}

  \underline{Разпределение на $\xi$} наричаме мярката
  \begin{displaymath}
    \Prob_\xi(A) \coloneqq \Prob(\xi \in A).
  \end{displaymath}

  Две случайни величини $\xi$ и $\eta$ наричаме \underline{независими}, ако за всички $A, B \in \F$ е изпълнено
  \begin{displaymath}
    \Prob(\xi \in A, \eta \in B) = \Prob_\xi(A) \Prob_\eta(B).
  \end{displaymath}

  Случайната величина $\xi$ наричаме \underline{дискретна} и казваме, че $\xi$ има \underline{дискретно разпределение}, ако тя приема крайно или изброимо много стойности $x_1, x_2, \ldots$ с вероятности съответно
  \begin{displaymath}
    p_k = P(\xi = x_k), k = 1, 2, \ldots.
  \end{displaymath}

  Множеството от стойности на $\xi$ ще бележим с $\Image(\xi) \coloneqq \{ x_1, x_2, \ldots \}$.
\end{definition}

\begin{theorem}\label{thm:rv-iff-pf}
  Редицата $p_1, p_2, \ldots$ са е редица от вероятности на някоя дискретна случайна величина тогава и само тогава, когато са изпълнени
  \begin{enumerate}
    \item\label{thm:rv-iff-pf.bounded} (неотрицателност) $0 \leq p_k$ за всяко $k = 1, 2, \ldots$
    \item\label{thm:rv-iff-pf.normed} (нормираност) $\sum_k p_k = 1$.
  \end{enumerate}
\end{theorem}

Теорема~\ref{thm:rv-iff-pf} ни дава обосновка да задаваме дискретни случайни величини изцяло чрез редици от вероятности без да задаваме вероятностни пространства. По тази причина понякога разпределение на дискретна случайна величина наричаме не съответната вероятностна мярка, а редицата от вероятностите.

\begin{proof}
  ($\implies$) Нека $\xi$ е дискретна случайна величина над вероятностното пространство $(\Omega, \F, \Prob)$ със стойности $x_1, x_2, \ldots$ и вероятности $p_1, p_2, \ldots$.

  Тъй като $\Prob: \F \to [0, 1]$ е вероятностна мярка, директно получаваме $p_k = \Prob(\xi = x_k) \in [0, 1]$ за всяко $k = 1, 2, \ldots$ и
  \begin{multline*}
    \sum_k p_k
    =
    \sum_k \Prob(\xi = x_k)
    =
    \sum_k \Prob(\{ \omega \in \Omega \mid \xi(\omega) = x_k \})
    =
    \Prob(\cup_k \{ \omega \in \Omega \mid \xi(\omega) = x_k \})
    = \\ =
    \Prob(\{ \omega \in \Omega \mid \xi(\omega) \in \Image(\xi) \})
    =
    \Prob(\xi \in \Image(\xi))
    =
    1.
  \end{multline*}

  ($\impliedby$) Нека редицата $p_1, p_2, \ldots$ удовлетворява условията~\ref{thm:rv-iff-pf.bounded} и~\ref{thm:rv-iff-pf.normed}. Предполагаме, че това са вероятности за някакви елементарни събития $\Omega = \{ x_1, x_2, \ldots \}$.

  Дефинираме случайната величина $\xi: \Omega \to \R, \xi(x_k) \coloneqq p_k$, която е измерима над $(\Omega, \PowerSet(\Omega))$, тъй като праобразът $\xi^{-1}(A)$ на всяко борелово множество $A \in \BorelAlgebra(\R)$ е подмножество на $\Omega$.

  Сега дефинираме $\Prob(A) \coloneqq \sum_{\omega \in A} \xi(\omega)$. Тази сума е добре дефинирана, тъй като редът $\sum_k p_k$ е абсолютно сходящ според~\ref{thm:rv-iff-pf.bounded} и следователно всеки подред също е абсолютно сходящ.

  $\Prob$ е вероятностна мярка над $(\Omega, \PowerSet(\Omega))$, тъй като
  \begin{enumerate}
    \item $\Prob(\varnothing) = 0$,
    \item $\Prob(A) = \sum_{\omega \in A} \xi(\omega) \geq 0$ за произволно събитие $A \subseteq \Omega$ според свойство~\ref{thm:rv-iff-pf.bounded},
    \item $\Prob(\cup_{i=1}^\infty A_i) = \sum_{\omega \in \cup_{i=1}^\infty A_i} \xi(\omega) = \sum_{i=1}^\infty \sum_{\omega \in A_i} \xi(\omega) = \sum_{i=1}^\infty \Prob(A_i)$,
    \item $\Prob(A) \leq 1$ за произволно събитие $A \subseteq \Omega$ според доказаната адитивност и свойство~\ref{thm:rv-iff-pf.normed}.
  \end{enumerate}
  Така построихме дискретна случайна величина $\xi$ над пространството $(\Omega, \PowerSet(\Omega), \Prob)$ с вероятности $p_1, p_2, \ldots$.
\end{proof}

\begin{proposition}
  Дискретните случайни величини над едно вероятностно пространство $(\Omega, \F, \Prob)$ образуват линейно пространство относно операциите събиране и умножение с число.
\end{proposition}
\begin{proof}
  Ще докажем само затвореността относно операциите, тъй като останалите аксиоми за линейно пространство са изпълнени по тривиални причини.

  Сумата $\xi + \eta$ на две дискретни случайни величини приема стойности $x + y$ за $x \in \Image(\xi)$ и $y \in \Image(\eta)$, които са не повече от изброимо много, следователно $\xi + \eta$ също е дискретна случайна величина.

  Произведението $c \xi$ за $c \in \R$ приема или само една стойност при $c = 0$, или същият брой стойности като $\xi$, следователно $c \xi$ също е дискретна случайна величина.
\end{proof}

\subsection{Очакване и моменти}

До края на темата ще считаме, че работим над вероятностното пространство $(\Omega, \F, \Prob)$.

\begin{definition}
  Нека $\xi$ е дискретна случайна величина със стойности $x_1, x_2, \ldots$. Дефинираме \underline{очакване на $\xi$} чрез
  \begin{displaymath}
    \Expect(\xi) \coloneqq \sum_k x_k \Prob(\xi = x_k) = \sum_{\omega \in \Omega} \xi(\omega) P(\{ \omega \}).
  \end{displaymath}
  Казваме, че $\xi$ има (крайно) очакване, ако горният ред е абсолютно сходящ.

  Случайни величини с очакване нула наричаме \underline{центрирани}.

  Очакване от константа $x \in \R$ дефинираме да бъде самата константа $x$.
\end{definition}

\begin{note}
  Формално, полагаме $\Expect(x) \coloneqq \Expect(\Ind_x)$, където $\Ind_x$ е индикатор за $x$, т.е.
  \begin{displaymath}
    \Prob(I_x = y) = \delta_{xy} = \begin{cases}
      1, x = y, \\
      0, x \neq y.
    \end{cases}
  \end{displaymath}

  Оттук директно следва $\Expect(x) = \Expect(\Ind_x) = x$.
\end{note}

\begin{proposition}\label{thm:expect-independent}
  За независими дискретни случайни величини $\xi$ и $\eta$ с крайно очакване е изпълнено
  \begin{displaymath}
    \Expect(\xi \eta) = \Expect(\xi) \Expect(\eta).
  \end{displaymath}
\end{proposition}
\begin{proof}
  Нека $x_1, x_2, \ldots$ и $y_1, y_2, \ldots$ са стойностите съответно на $\xi$ и $\eta$. Тогава
  \begin{multline*}
    \Expect(\xi) \Expect(\eta)
    =
    \left( \sum_i x_i \Prob(\xi = x_i) \right) \left( \sum_j y_j \Prob(\eta = y_j) \right)
    =
    \sum_{k=1}^\infty \sum_{m=1}^k x_m y_{k-m} \Prob(\xi = x_m) \Prob(\eta = y_{k-m})
    = \\ =
    \sum_{k=1}^\infty \sum_{m=1}^k x_m y_{k-m} \Prob(\xi = x_m, \eta = y_{k-m})
    =
    \sum_{i, j} x_i y_j \Prob(\xi = x_i, \eta = y_j)
    =
    \Expect(\xi \eta).
  \end{multline*}
\end{proof}

\begin{proposition}\label{thm:expect-linear}
  Очакването е линеен функционал над подпространството от случайни величини над $(\Omega, \F, \Prob)$, за които очакването съществува.
\end{proposition}
\begin{proof}
  Директно проверяваме дефиницията за линеен функционал:
  \begin{enumerate}
    \item За две дискретни случайни $\xi$ и $\eta$ величини с крайно очакване имаме
    \begin{multline*}
      \Expect(\xi + \eta)
      =
      \sum_{\omega \in \Omega} (\xi + \eta) (\omega) P(\{ \omega \})
      =
      \sum_{\omega \in \Omega} [\xi (\omega) + \eta (\omega)] P(\{ \omega \})
      = \\ =
      \sum_{\omega \in \Omega} \xi (\omega) P(\{ \omega \}) + \sum_{\omega \in \Omega} \eta (\omega) P(\{ \omega \})
      =
      \Expect(\xi) + \Expect(\eta).
    \end{multline*}

    \item За дискретна случайна величина $\xi$ със стойности $x_1, x_2, \ldots$ и крайно очакване и константа $c \in \R$ по твърдение~\ref{thm:lotus} имаме
    \begin{displaymath}
      \Expect(c \xi)
      =
      \sum_k (c x_k) P(\xi = x_k)
      =
      c \sum_k x_k P(\xi = x_k)
      =
      c \Expect(\xi).
    \end{displaymath}
  \end{enumerate}

  Видяхме и това, че дискретните случайни величини с крайно очакване са затворени относно събиране и умножение с число, с което доказваме, че те образуват линейно подпространство на всички дискретни случайни величини.
\end{proof}

\begin{proposition}\label{thm:lotus}
  Ако $\xi$ е (реална) дискретна случайна величина със стойности $x_1, x_2, \ldots$ и $\psi: \Complex \to \Complex$ е измерима функция, то $\psi(\xi)$ е (комплексна) случайна и е изпълнено
  \begin{displaymath}
    \Expect(\psi(\xi))
    =
    \sum_k \psi(x_k) P(\xi = x_k),
  \end{displaymath}
  при условие, че горният ред а абсолютно сходящ.
\end{proposition}

\begin{note}
  Допускаме $\phi$ да бъде комплексна функция, тъй като това ни е необходимо за дефинирането на характеристични функции.
\end{note}

\begin{proof}
  Образът на крайно или измеримо множество е най-много измеримо, затова $\psi(\xi)$ приема не повече от изброимо много различни стойности и следователно е дискретна случайна величина. Нека стойностите на $\psi(\xi)$ са $y_1, y_2, \ldots$. Праобразите $\psi^{-1}(y_i)$ на $y_i, i = 1, 2, \ldots$ са крайни или изброими, непресичащи се и $\Image(\xi) = \cup_i \psi^{-1}(y_i)$. Имаме
  \begin{multline*}
    \Expect(\psi(\xi))
    =
    \sum_i y_i P(\psi(\xi) = y_i)
    =
    \sum_i y_i \sum_{x \in \psi^{-1}(y_i)} P(\xi = x)
    = \\ =
    \sum_i \sum_{x \in \psi^{-1}(y_i)} \psi(x) P(\xi = x)
    =
    \sum_k \psi(x_k) P(\xi = x_k).
  \end{multline*}
\end{proof}

Доказаните в твърдения~\ref{thm:expect-independent},~\ref{thm:expect-linear} и~\ref{thm:lotus} свойства на очакването значително опростяват работата с него.

\begin{definition}
  \underline{Ковариация на случайните величини $\xi$ и $\eta$} наричаме
  \begin{displaymath}
    \Cov(\xi, \eta)
    \coloneqq
    \Expect((\xi - \Expect \xi) (\eta - \Expect \eta)).
  \end{displaymath}

  \underline{Дисперсия или вариация на случайната величина $\xi$} наричаме
  \begin{displaymath}
    \Var(\xi)
    \coloneqq
    \Cov(\xi, \xi)
    =
    \Expect \left({(\xi - \Expect \xi)}^2 \right)
    =
    \Expect(\xi^2 - 2 \xi \Expect \xi + {\Expect(\xi)}^2)
    =
    \Expect(\xi^2) - 2 {\Expect(\xi)}^2 + {\Expect(\xi)}^2
    =
    \Expect(\xi^2) - {\Expect(\xi)}^2.
  \end{displaymath}

  Числото $\Expect(\xi^n)$ наричаме \underline{$n$-ти момент на $\xi$}, а $\Expect \left( {(\xi - \Expect \xi)}^n \right)$ наричаме \underline{$n$-ти централен момент на $\xi$}.

  Дисперсията всъщност е просто вторият централен момент. Коренът на дисперсията се нарича стандартно отклонение и често се бележи със $\sigma_\xi$.

  Две случайни величини се наричат \underline{ортогонални}, ако ковариацията им е $0$, защото ковариацията играе ролята на скаларно произведение в пространството $\LSpace^2$ от случайни величини с краен втори момент.

  Случайни величини със стандартно отклонение единица наричаме \underline{нормирани}, тъй като стандартно отклонение играе ролята на норма в $\LSpace^2$.
\end{definition}

\begin{proposition}\label{thm:orthogonal-independent}
  Ако две случайни величини са независими и имат крайно очакване, те са ортогонални.
\end{proposition}
\begin{proof}
  Нека $\xi$ и $\eta$ са независими и имат крайно очакване. Полагаме $\xi' \coloneqq \xi - \Expect(\xi)$ и $\eta' \coloneqq \eta - \Expect(\eta)$. Тогава
  \begin{displaymath}
    \Cov(\xi, \eta)
    =
    \Expect((\xi - \mu) (\eta - \nu))
    =
    \Expect(\xi' \eta')
    =
    \Expect(\xi') \Expect(\eta')
    =
    0 \cdot 0
    =
    0.
  \end{displaymath}
\end{proof}

\begin{proposition}\label{thm:lower-order-moments}
  Ако $\Expect(\xi^n)$ съществува, съществуват и моментите от по-нисък ред.
\end{proposition}
\begin{proof}
  Първо да забележим, че за $y \in (0, 1)$ имаме ${\Prob(\xi = x_k)}^y < \Prob(\xi = x_k)$. Ще докажем, че $\Expect({\Abs{\xi}}^{n-1})$ съществува. Прилагаме неравенството на Йенсен за редове:
  \begin{multline*}
    \Expect({\Abs{\xi}}^{n-1})
    \leq
    {\Expect({\Abs{\xi}}^{n-1})}^{\frac n {n-1}}
    =
    {\left( \sum_k {\Abs{x_k}}^{n-1} \Prob(\xi = x_k) \right)}^{\frac n {n-1}}
    \leq
    \sum_k {\left({\Abs{x_k}}^{n-1} \Prob(\xi = x_k) \right)}^{\frac n {n-1}}
    < \\ <
    \sum_k {\left({\Abs{x_k}}^{n-1}\right)}^{\frac n {n-1}} \Prob(\xi = x_k)
    =
    \sum_k {\Abs{x_k}}^n \Prob(\xi = x_k)
    =
    \Expect({\Abs{\xi}}^n).
  \end{multline*}
\end{proof}

\subsection{Пораждащи, пораждащи моментите и характеристични функции}

\begin{definition}
  \underline{Пораждаща функция на $\xi$} наричаме
  \begin{displaymath}
    \PGF_\xi (z) \coloneqq \Expect(z^\xi).
  \end{displaymath}

  \underline{Пораждаща моментите функция на $\xi$} наричаме
  \begin{displaymath}
    \MGF_\xi (t) \coloneqq \Expect(e^{t\xi}).
  \end{displaymath}

  \underline{Характеристична функция на $\xi$} наричаме
  \begin{displaymath}
    \Char_\xi (t) \coloneqq \Expect(e^{it\xi}).
  \end{displaymath}

  Изпълнено е $\Char_\xi(t) = \MGF_\xi(it) = \PGF_\xi(e^{it})$.
\end{definition}

\begin{note}
  Дефинициите за моменти и функции от очакването се пренасят без изменение за случайни величини, които не са дискретни. Пораждащите функции, обаче, се полезни само за случайни величини, които приемат неотрицателни цели стойности.
\end{note}

\begin{theorem}[Свойства на пораждащите функции]
  Нека $\xi$ и $\eta$ са независими целочислени случайни величини със стойности $0, 1, \ldots$ (възможно е $P(\xi = k) > 0$ само за краен брой $k$).

  За пораждащата функция $\PGF_\xi$ са изпълнени следните свойства
  \begin{enumerate}
    \item $\PGF_\xi(z)$ е аналитична функция поне в $-1 < z < 1$.
    \item $P(\xi = m) = \frac {\PGF_\xi^{(m)}} {m!} (0)$, където $\PGF_\xi^{(m)}$ е $m$-тата производна на $\PGF_\xi$.
    \item Ако пораждащите функции на $\xi$, $\eta$ и $\xi + \eta$ съществуват в точка $z \in \R$, имаме
    \begin{displaymath}
      \PGF_{\xi + \eta}(z) = \PGF_\xi(z) \PGF_\eta(z)
    \end{displaymath}

    \item Ако пораждащите функции на две целочислени дискретни случайни величини съвпадат, самите случайни величини съвпадат.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \mbox{}
  \begin{enumerate}
    \item $\PGF_\xi(z)$ се дефинира чрез степенен ред. За да докажем, че тя е аналитична в някоя област, е достатъчно да покажем сходимост на степенния ред в тази област. Използваме това, че за произволно събитие $A$ имаме $0 \leq \Prob(A) \leq 1$, и оценяваме редът отгоре
    \begin{displaymath}
      \Abs{\PGF_\xi(z)}
      =
      \Abs{\Expect(z^\xi)}
      =
      \Abs{\sum_{k=0}^\infty z^k \Prob(\xi = k)}
      \leq
      \sum_{k=0}^\infty \Abs{z^k \Prob(\xi = k)}
      =
      \sum_{k=0}^\infty \Abs{z}^k \Prob(\xi = k)
      \leq
      \sum_{k=0}^\infty \Abs{z}^k.
    \end{displaymath}
    Последният ред е сходящ при $\Abs z < 1$.

    \item Разглеждаме степенния ред на $\PGF_\xi$:
    \begin{displaymath}
      \PGF_\xi(z)
      =
      \sum_{k=0}^\infty z^k \Prob(\xi = k)
      =
      \sum_{k=0}^{m-1} z^k \Prob(\xi = k) + z^m \Prob(\xi = m) + \sum_{k=m+1}^\infty z^k \Prob(\xi = k).
    \end{displaymath}

    Аналитичността на $\PGF_\xi$ ни позволява да диференцираме очакването почленно. След $m$-кратно диференциране получаваме
    \begin{displaymath}
      \PGF_\xi^{(m)}(z)
      =
      \sum_{k=0}^{m-1} k! \cdot 0 \Prob(\xi = k) + m! \Prob(\xi = m) + \sum_{k=m+1}^\infty (k-m) \cdots (k-1) k z^{k-m} \Prob(\xi = k).
    \end{displaymath}

    Следователно $\PGF_\xi^{(m)}(0) = m! \Prob(\xi = m)$.

    \item Тъй като $\xi$ и $\eta$ са независими, за произволно $z \in \R$ величините $z^\xi$ и $z^\eta$ са независими и
    \begin{displaymath}
      \PGF_{\xi + \eta}(z)
      =
      \Expect(z^{\xi + \eta})
      =
      \Expect(z^\xi z^\eta)
      =
      \Expect(z^\xi) \Expect(z^\eta)
      =
      \PGF_\xi(z) \PGF_\eta(z).
    \end{displaymath}

    \item Директно следва от изразяването на стойностите на $\xi$ и $\eta$ чрез производните на пораждащите ги функции.
  \end{enumerate}
\end{proof}

\begin{theorem}[Свойства на пораждащите моментите функции]
  Нека $\xi$ и $\eta$ са независими дискретни случайни величини.

  За пораждащите моментите функции $\MGF_\xi$ и $\MGF_\eta$ са изпълнени следните свойства
  \begin{enumerate}
    \item В общия случай пораждащата моментите функция съществува само в $0$. Ако тя съществува в околност на $0$, то тя е гладка в тази околност, съществуват всички моменти и е изпълнено $\Expect(\xi^m) = \MGF_\xi^{(m)} (0)$ за $m = 1, 2, \ldots$.

    \item Ако пораждащите моментите функции на $\xi$, $\eta$ и $\xi + \eta$ съществуват в точка $t \in \R$, имаме
    \begin{displaymath}
      \MGF_{\xi + \eta}(t) = \MGF_\xi(t) \MGF_\eta(t).
    \end{displaymath}

    \item Ако $\MGF_\xi$ и $\MGF_\eta$ имат обща дефиниционна област, в която те съвпадат, то $\xi$ и $\eta$ също съвпадат.
  \end{enumerate}
\end{theorem}
\begin{proof}
  Нека стойностите на $\xi$ са $x_1, x_2, \ldots$.

  \mbox{}
  \begin{enumerate}
    \item Пораждащата моментите функция винаги съществува в $0$, тъй като $\MGF_\xi(0) = \Expect(e^{0\xi}) = \Expect(1) = 1$.

    Нека $\MGF_\xi$ съществува в околност $U$ на $0$. Без ограничение на общността ще считаме, че $U$ е ограничена. Полагаме $\tau \coloneqq \min(-\inf U, \sup_U)$. Тогава сумата $\MGF_\xi(-\tau) + \MGF_\xi(\tau)$ е крайна. Развиваме тази сума в ред на Тейлър:
    \begin{displaymath}
      \MGF_\xi(-\tau) + \MGF_\xi(\tau)
      =
      \Expect(e^{-\tau\xi} + e^{\tau\xi})
      =
      \Expect\left( 2 \sum_{k=0}^\infty \frac {\xi^{2k}} {(2k)!} \tau^{2k} \right)
      =
      2 \sum_{k=0}^\infty \frac {\Expect(\xi^{2k})} {(2k)!} \tau^{2k}.
    \end{displaymath}

    Внасянето на очакването е възможно, защото всички членове на реда са неотрицателни. От $\Expect(\xi^{2m}) = \Expect(\Abs{\xi^{2m}})$ се вижда, че всички четни моменти съществуват. Според твърдение~\ref{thm:lower-order-moments} съществуват и всички нечетни моменти.

    Остава да докажем, че са налице условията за $m$-кратно почленно диференциране на реда $\Char_\xi(t) = \Expect (e^{t\xi})$ в областта $\frac 1 {2^m} U = \{ \frac t {2^m} U \mid t \in U \}$.

    Разглеждаме очакването на $m$-тата производна $\xi^m e^{t \xi}$ на $e^{t \xi}$ по $t$. Налице са условията за почленно диференциране на ред:
    \begin{enumerate}
      \item За $m > 0$ прилагаме неравенството на Коши-Буняковски-Шварц, за да докажем, че $\Expect \left( \xi^m e^{t \xi} \right)$ съществува за $t \in \frac 1 {2^m} U$:
      \begin{multline*}
        {\left(\Expect \left( \xi^m e^{t \xi} \right) \right)}^2
        =
        {\left(\sum_k x_k^m e^{t x_k} \Prob(\xi = x_k) \right)}^2
        = \\ =
        {\left(\sum_k (x_k^m \sqrt{\Prob(\xi = x_k)}) (e^{t x_k} \sqrt{\Prob(\xi = x_k)}) \right)}^2
        \leq \\ \leq
        \sum_k x_k^{2m} \Prob(\xi = x_k)
        \sum_k e^{2t x_k} \Prob(\xi = x_k)
        = \\ =
        \Expect(\xi^{2m})
        \Expect(e^{2t \xi})
        =
        \Expect(\xi^{2m})
        \Char_\xi(2t).
      \end{multline*}

      \item Функцията $x \mapsto x^m e^{t x}$ е диференцируема по $t$ за всяко $x \in \Image(\xi)$.
      \item Производната на $x^m e^{t x}$ по $t$ се мажорира по абсолютна стойност от
      \begin{displaymath}
        \Abs{x^{m+1} e^{t x}}
        \leq
        {\Abs{x}}^{m+1} \Abs{e^{t x}}
        \leq
        {\Abs{x}}^{m+1} e^{\Abs{t x}}
        \leq
        {\Abs{x}}^{m+1} e^{\tau \Abs{x}},
      \end{displaymath}
      където мажорантата не зависи от $t$.
    \end{enumerate}

    По индукция за $m = 1, 2, \ldots$ получаваме $\MGF^{(m)}_\xi(t) = i^m \Expect(\xi^m e^{t \xi})$ в $\frac 1 {2^m} U$. В частност, $\MGF^{(m)}_\xi(0) = \Expect(\xi^m e^{0 \xi}) = \Expect(\xi^m)$.

    \item Ако пораждащите моментите функции съществуват в $t \in \R$, тъй като $\xi$ и $\eta$ са независими, случайните величини $e^{t\xi}$ и $e^{t\eta}$ също са независими и
    \begin{displaymath}
      \MGF_{\xi + \eta}(t)
      =
      \Expect(e^{t(\xi + \eta)})
      =
      \Expect(e^{t\xi} e^{t\eta})
      =
      \Expect(e^{t\xi}) \Expect(e^{t\eta})
      =
      \MGF_\xi(t) \MGF_\eta(t).
    \end{displaymath}

    \item Нека $z_1, z_2, \ldots$ е обединение на стойностите на $\xi$ и $\eta$. Ако функциите $\MGF_\xi$ и $\MGF_\eta$ съвпадат в областта си на дефиниция $U$, за $t \in U$ имаме
    \begin{align*}
      \MGF_\xi(t) - \MGF_\eta(t) &= 0
      \\
      \sum_k e^{t z_k} \Prob(\xi = z_k) - \sum_k e^{t z_k} \Prob(\eta = z_k) &= 0
      \\
      \sum_k e^{t z_k} (\Prob(\xi = z_k) - \Prob(\eta = z_k)) &= 0.
    \end{align*}
    Последното равенство е изпълнено за всяко $t \in U$ точно когато $\Prob(\xi = z) = \Prob(\xi = z)$ за всяко $z \in \Image(\xi) \cup \Image(\eta)$. Следователно $\xi$ и $\eta$ приемат едни и същи стойности $\Image(\xi) = \Image(\eta)$ с една и съща вероятност и тъй като и двете са дискретни, те съвпадат.
  \end{enumerate}
\end{proof}

\begin{theorem}[Свойства на характеристичните функции]
  Нека $\xi$ и $\eta$ са независими дискретни случайни величини.

  За характеристичните функции $\Char_\xi$ и $\Char_\eta$ са изпълнени следните свойства
  \begin{enumerate}
    \item $\Char_\xi$ съществува и е равномерно непрекъсната навсякъде върху реалната права.

    \item Ако $\xi^n$ има краен $n$-ти момент, е изпълнено $\Expect(\xi^m) = i^{-m} \Char_\xi^{(m)} (0)$ за $m = 1, \ldots, n$.

    \item За всяко $t \in \R$ имаме
    \begin{displaymath}
      \Char_{\xi + \eta}(t) = \Char_\xi(t) \Char_\eta(t).
    \end{displaymath}

    \item Ако $\Char_\xi$ и $\Char_\eta$ съвпадат, то $\xi$ и $\eta$ също съвпадат.
  \end{enumerate}
\end{theorem}
\begin{proof}
  Нека стойностите на $\xi$ са $x_1, x_2, \ldots$.

  \begin{enumerate}
    \item За да докажем, че $\Char_\xi$ е дефинирана навсякъде в $\R$, оценяваме отгоре абсолютната стойност на $\Char_\xi$ за $t \in \R$:
    \begin{displaymath}
      \Abs{\Char_\xi(t)}
      =
      \Abs{\Expect(e^{it\xi})}
      =
      \Abs{\sum_k e^{it x_k} \Prob(\xi = x_k)}
      \leq
      \sum_k \Abs{e^{it x_k}} \Prob(\xi = x_k)
      =
      \sum_k \Prob(\xi = x_k)
      =
      1.
    \end{displaymath}

    За да докажем и равномерната непрекъснатост в $\R$, първо оценяваме отгоре израза
    \begin{multline*}
      \Abs{\Char_\xi(t + h) - \Char_\xi(t)}
      =
      \Abs{\Expect(e^{i(t + h)\xi}) - \Expect(e^{it\xi})}
      = \\ =
      \Abs{\Expect(e^{it\xi} (e^{ih\xi} - 1))}
      =
      \Abs{\sum_k e^{it x_k} (e^{ih x_k} - 1) \Prob(\xi = x_k)}
      \leq \\ \leq
      \sum_k \Abs{e^{it x_k}} \Abs{e^{ih x_k} - 1} \Prob(\xi = x_k)
      =
      \sum_k \Abs{e^{ih x_k} - 1} \Prob(\xi = x_k).
    \end{multline*}

    Фиксираме $\varepsilon > 0$. Избираме константа $c_\varepsilon \in \R$ такава, че $\Prob(\Abs{\xi} > c_\varepsilon) < \frac \varepsilon 3$.
    Въвеждаме две множества от индекси: $A \coloneqq \{ k = 1, 2, \ldots \mid \Abs{x_k} \leq c_\varepsilon \}$ и $B = \ZPos \setminus A$.

    Ще използваме, че за всяко $z \in \Complex$ неравенството на Йенсен ни дава
    \begin{displaymath}
      \Abs{e^{iz} - 1}
      =
      \Abs{i \int_0^z e^{it} dt}
      \leq
      \int_0^{\Abs{z}} \Abs{e^{it}} dt
      =
      \int_0^{\Abs{z}} dt
      =
      \Abs{z}.
    \end{displaymath}

    За $k \in A$ имаме
    \begin{displaymath}
      \sum_{k \in A} \Abs{e^{ih x_k} - 1} \Prob(\xi = x_k)
      \leq
      \sum_{k \in A} \Abs{h x_k} \Prob(\xi = x_k)
      \leq
      c_\varepsilon \Abs h \sum_{k \in A} \Prob(\xi = x_k)
      \leq
      c_\varepsilon \Abs h.
    \end{displaymath}

    За $k \in B$ имаме

    \begin{displaymath}
      \sum_{k \in B} \Abs{e^{ih x_k} - 1} \Prob(\xi = x_k)
      \leq
      \sum_{k \in B} \left( \Abs{e^{ih x_k}} + 1 \right) \Prob(\xi = x_k)
      =
      2 \sum_{k \in B} \Prob(\xi = x_k)
      <
      \frac {2\varepsilon} 3.
    \end{displaymath}

    За целият ред тогава получаваме
    \begin{displaymath}
      \sum_k \Abs{e^{ih x_k} - 1} \Prob(\xi = x_k)
      <
      c_\varepsilon \Abs{h} + 2 \varepsilon.
    \end{displaymath}

    Полагаме $\delta = \frac \varepsilon {3 c_\varepsilon}$.

    Тогава за $\Abs h < \delta$ имаме
    \begin{displaymath}
      \Abs{\Char_\xi(t + h) - \Char_\xi(t)}
      <
      c_\varepsilon \Abs{h} + \frac {2\varepsilon} 3
      <
      \frac {\varepsilon} 3 + \frac {2\varepsilon} 3
      =
      \varepsilon.
    \end{displaymath}

    Числото $\delta$ зависи само от $\varepsilon$, следователно $\Char_\xi(t)$ е равномерно непрекъсната върху цялата реална права.

    \item Нека съществува моментът $\Expect \xi^n$. Тогава съществуват и моментите от по-нисък ред.

    Ще докажем, че са налице условията за $m$-кратно почленно диференциране на реда $\Char_\xi(t) = \Expect (e^{it \xi})$.

    Разглеждаме очакването на $m$-тата производна $i^m \xi^m e^{it \xi}$ на $e^{it \xi}$ по $t$. Налице условията за почленно диференциране на ред:
    \begin{enumerate}
      \item $\Expect \left( i^m \xi^m e^{it \xi} \right)$ съществува за $t \in \R$, тъй като
      \begin{multline*}
        \Abs{\Expect \left( i^m \xi^m e^{it \xi} \right)}
        =
        \Abs{\Expect \left( \xi^m e^{it \xi} \right)}
        =
        \Abs{\sum_k x_k^m e^{it x_k} \Prob(\xi = x_k)}
        \leq
        \sum_k \Abs{x_k^m e^{it x_k} \Prob(\xi = x_k)}
        = \\ =
        \sum_k \Abs{x_k^m} \Abs{e^{it x_k}} \Prob(\xi = x_k)
        =
        \sum_k \Abs{x_k^m} \Prob(\xi = x_k)
        =
        \Expect \left( {\Abs{\xi^m}} \right).
      \end{multline*}
      Последното очакване е крайно, тъй като $\Expect(\Abs{\xi^0}) = 1$, а за $m > 0$ по условие редът $\Expect(\xi^m)$ е абсолютно сходящ.
      \item Функцията $x \mapsto i^m x^m e^{it x}$ е диференцируема по $t$ за всяко $x \in \Image(\xi)$.
      \item Производната на $i^m x^m e^{it x}$ по $t$ се мажорира по абсолютна стойност от $\Abs{x^{m+1} e^{it x}} \leq {\Abs{x}}^{m+1}$, където мажорантата не зависи от $t$.
    \end{enumerate}

    По индукция за $m = 1, \ldots, n$ получаваме $\Char^{(m)}_\xi(t) = i^m \Expect(\xi^m e^{t \xi})$. В частност, $\Char^{(m)}_\xi(0) = i^m \Expect(\xi^m e^{0 \xi}) = i^m \Expect(\xi^m)$.

    \item Тъй като $\xi$ и $\eta$ са независими, за произволно $t \in \R$ величините $e^{t\xi}$ и $e^{t\eta}$ са независими и
    \begin{displaymath}
      \Char_{\xi + \eta}(t)
      =
      \Expect(e^{it(\xi + \eta)})
      =
      \Expect(e^{it\xi} e^{it\eta})
      =
      \Expect(e^{it\xi}) \Expect(e^{it\eta})
      =
      \Char_\xi(t) \Char_\eta(t).
    \end{displaymath}

    \item Нека $z_1, z_2, \ldots$ е обединение на стойностите на $\xi$ и $\eta$. Ако функциите $\Char_\xi$ и $\Char_\eta$ съвпадат, имаме
    \begin{align*}
      \Char_\xi(t) - \Char_\xi(t) &= 0
      \\
      \sum_k e^{i t z_k} \Prob(\xi = z_k) - \sum_k e^{i t z_k} \Prob(\xi = z_k) &= 0
      \\
      \sum_k e^{i t z_k} (\Prob(\xi = z_k) - \Prob(\xi = y_k)) &= 0.
    \end{align*}
    Последното равенство е изпълнено за всяко $t \in \Complex$ точно когато $\Prob(\xi = z) = \Prob(\xi = z)$ за всяко $z \in \Image(\xi) \cup \Image(\eta)$. Следователно $\xi$ и $\eta$ приемат едни и същи стойности $\Image(\xi) = \Image(\eta)$ с една и съща вероятност и тъй като и двете са дискретни, те съвпадат.
  \end{enumerate}
\end{proof}

\subsection{Често срещани дискретни разпределения}

\subsubsection{Дискретно равномерно разпределение}

\begin{definition}
  Казваме, че случайната величина $\xi$ има \underline{дискретно равномерно разпределение} над множеството $N$ с размер $n$ и пишем $\xi \in \DUniform(N)$, ако за всяко $k \in N$ е изпълнено
  \begin{displaymath}
    \Prob(\xi = k) = \frac 1 n.
  \end{displaymath}

  Дефиницията е коректна, тъй като $\frac 1 n > 0$ и $\sum_{k \in N} \Prob(\xi = k) = \sum_{k \in N} \frac 1 n = \frac n n = 1$.

  За простота обикновено считаме, че $N$ е множеството на целите числа между две положителни цели числа $a$ и $b$, т.е. $N = \{ a, a + 1, \ldots, b - 1, b \}$. В такъв случай бележим $\xi \in \DUniform(a, b)$.
\end{definition}

Равномерното дискретно разпределение моделира експерименти с краен брой изходи, за които предполагаме, че са равновероятни. Такива са например разни игри - боята на случайно избрана игрална карта или броят точки, паднали се при хвърляне на зар. Друг пример идва от втората световна война, където статистици са се опитали да оценят броя $n$ произведени от Германия танкове, предполагайки, че серийните им номера са равномерно разпределени между $1$ и $n$.

За пораждащата функция, очакването и дисперсията на $\xi \in \DUniform(a, b)$ имаме
\begingroup
\allowdisplaybreaks
\begin{align*}
  \PGF_\xi(z)
  &=
  \Expect(z^\xi)
  =
  \frac 1 {b-a+1} \sum_{k=a}^b z^k
  =
  \frac 1 {b-a+1} \left( \sum_{k=1}^b z^k - \sum_{k=1}^{a-1} z^k \right)
  = \\ &=
  \frac 1 {b-a+1} \left(\frac {z^{b+1} - 1} {z - 1} - \frac {z^a - 1} {z - 1} \right)
  =
  \boxed{\frac {z^{b+1} - z^a} {(b-a+1)(z-1)}},
  \\
  \Expect(\xi)
  &=
  \frac 1 {b-a+1} \sum_{k=a}^b k
  =
  \frac 1 {b-a+1} \left( \sum_{k=1}^b k - \sum_{k=1}^{a-1} k \right)
  =
  \frac 1 {b-a+1} \left( \frac {b(b+1)} 2 - \frac {(a-1)a} 2 \right)
  = \\ &=
  \frac {b^2 + b - a^2 + a} {2(b-a+1)}
  =
  \frac {(b-a)(b+a) + (b+a)} {2(b-a+1)}
  =
  \boxed{\frac {a+b} 2},
  \\
  \Expect(\xi^2)
  &=
  \frac 1 {b-a+1} \sum_{k=a}^b k^2
  =
  \frac 1 {b-a+1} \left( \sum_{k=1}^b k^2 - \sum_{k=1}^{a-1} k^2 \right)
  = \\ &=
  \frac 1 {b-a+1} \left( \frac {b(b+1)(2b+1)} 6 - \frac {(a-1)a(2a-1)} 6 \right)
  = \\ &=
  \frac {b(2b^2 + 3b + 1) - b(2a^2 - 3a + 1)} {6(b-a+1)}
  =
  \frac {2(b^3 - a^3) + 3(b^2 + a^2) + (b-a)} {6(b-a+1)}
  = \\ &=
  \frac {2[{(b-a)}^3 + 3b^2a - 3ba^2] + 3[{(b-a)}^2 + 2ba] + (b-a)} {6(b-a+1)}
  = \\ &=
  \frac {(b-a) [2{(b-a)}^2 + 3(b-a) + 1] + 6ba(b-a+1)} {6(b-a+1)}
  = \\ &=
  \frac {(b-a) [2(b^2 - 2ba + a^2 + 2b - 2a + 1) - (b-a+1)] + 6ba(b-a+1)} {6(b-a+1)}
  = \\ &=
  \frac {(b-a) [2{(b-a+1)}^2 - (b-a+1)] + 6ba(b-a+1)} {6(b-a+1)}
  = \\ &=
  \frac {(b-a) [2(b-a+1)-1] + 6ba} 6
  =
  \boxed{\frac {2b^2+2ba+2a^2+b-a} 6},
  \\
  \Var(\xi)
  &=
  \Expect(\xi^2) - {\Expect(\xi)}^2
  =
  \frac {2b^2+2ba+2a^2+b-a} 6 - {\left( \frac {b+a} 2 \right)}^2
  = \\ &=
  \frac {2(2b^2+2ba+2a^2+b-a) - 3{b^2+2ba+a^2}} {12}
  =
  \frac {b^2-2ba+a^2+2b-2a} {12}
  =
  \boxed{\frac {{(b-a+1)}^2-1} {12}}.
\end{align*}
\endgroup

\subsubsection{Биномно разпределение}

\begin{definition}
  Казваме, че случайната величина $\xi$ има \underline{биномно разпределение} с обем $n \in \ZPos$ и вероятност $p \in (0, 1)$ и пишем $\xi \in \DBinomial(n, p)$, ако за всяко $k = 0, 1, \ldots, n$ е изпълнено
  \begin{displaymath}
    \Prob(\xi = k) = {n \choose k} p^k {(1-p)}^{n-k}.
  \end{displaymath}

  Дефиницията е коректна, тъй като $\Prob(\xi = k) > 0$ за $k = 0, \ldots, n$ и от биномната теорема имаме
  \begin{displaymath}
    \sum_{k=0}^n \Prob(\xi = k)
    =
    \sum_{k=0}^n {n \choose k} p^k {(1-p)}^{n-k}
    =
    {(p+(1-p))}^n = 1.
  \end{displaymath}

  Частният случай $\DBinomial(1, p)$ наричаме \underline{разпределение на Бернули} и бележим с $\DBernoulli(p)$.
\end{definition}

Биномното разпределение моделира брой успехи сред общо $n$ независими опита с еднаква вероятност $p$. Тога го прави изключително приложимо - от моделиране на количеството ръце с поне един туз при $n$ раздавания на игрални карти до моделиране на броя освободени невротрансмитери в химичните синапси на мозъка за единица време.

За пораждащата моментите функция, очакването и дисперсията на $\xi \in \DBinomial(n, p)$ имаме
\begingroup
\allowdisplaybreaks
\begin{align*}
  \MGF_\xi(t)
  &=
  \Expect(e^{t\xi})
  =
  \sum_{k=0}^n {n \choose k} e^{tk} p^k {(1-p)}^{n-k}
  =
  \sum_{k=0}^n {n \choose k} {\left( e^t p \right)}^k {(1-p)}^{n-k}
  =
  \boxed{{\left( e^t p + (1-p) \right)}^n},
  \\
  \MGF'_\xi(t)
  &=
  \boxed{n p e^t {\left( e^t p + (1-p) \right)}^{n-1}},
  \\
  \MGF''_\xi(t)
  &=
  n p \left[ e^t \cdot {\left( e^t p + (1-p) \right)}^{n-1} + e^t \cdot (n-1) p {\left( e^t p + (1-p) \right)}^{n-2} \right]
  = \\ &=
  n p e^t {\left( e^t p + (1-p) \right)}^{n-2} (e^t p + (1-p) + (n-1)p)
  = \\ &=
  \boxed{n p e^t {\left( e^t p + (1-p) \right)}^{n-2} (np + e^t p - 2p + 1)},
  \\
  \Expect(\xi)
  &=
  \MGF'_\xi(0)
  =
  \boxed{np},
  \\
  \Expect(\xi^2)
  &=
  \MGF''_\xi(0)
  =
  \boxed{np(np - p + 1)}
  \\
  \Var(\xi)
  &=
  \Expect(\xi^2) - {\Expect(\xi)}^2
  =
  np(np - p + 1) - {(np)}^2
  =
  \boxed{np(1 - p)}.
\end{align*}
\endgroup

Както става ясно от видът на пораждащата моментите функция, ако $\xi_1, \ldots, \xi_n \in \DBernoulli(p)$, то сумата им има разпределение $\DBinomial(n, p)$. Нещо повече, сумата на случайни величини с разпределения $\DBinomial(n, p)$ и $\DBinomial(m, p)$ има разпределение $\DBinomial(n + m, p)$.

Биномното разпределение е изиграло важна историческа роля, тъй като за него първо са формулирани известни гранични теореми.

\begin{theorem}[Бернули, предшественик на законите за големите числа]\label{thm:bernoulli}
  Нека $\xi_1, \xi_2, \ldots$ са независими и имат разпределение $\DBinomial(n, p)$. Тогава
  \begin{displaymath}
    \frac 1 n \sum_{k=1}^n \xi_k
    \to
    \Ind_p
  \end{displaymath}
  по вероятност.
\end{theorem}

\begin{theorem}[Моавър-Лаплас, предшественик на централните гранични теореми]\label{thm:moivre-laplace}
  Ако $\xi \in \DBinomial(n, p)$, тогава
  \begin{displaymath}
    \frac {\xi - \Expect(\xi)} {\sigma_\xi}
    =
    \frac {\xi - np} {\sqrt{np(1-p)}}
  \end{displaymath}
  клони по вероятност към стандартно нормално разпределение при $n \to \infty$.
\end{theorem}

\subsubsection{Геометрично разпределение}

\begin{definition}
  Казваме, че случайната величина $\xi$ има \underline{геометрични разпределение} с вероятност $p \in (0, 1)$ и пишем $\xi \in \DGeom(p)$, ако за всяко $k = 1, 2, \ldots$ е изпълнено
  \begin{displaymath}
    \Prob(\xi = k) = {(1-p)}^{k-1} p.
  \end{displaymath}

  Дефиницията е коректна, тъй като $\Prob(\xi = k) > 0$ за $k \in \ZPos$ и
  \begin{displaymath}
    \sum_{k=1}^\infty \Prob(\xi = k)
    =
    \sum_{k=1}^\infty {(1-p)}^{k-1} p
    =
    p \sum_{k=0}^\infty {(1-p)}^k
    =
    p \frac 1 {1-(1-p)}
    =
    1.
  \end{displaymath}

  Понякога се ползва алтернативна дефиниция, при която за $k = 0, 1, \ldots$
  \begin{displaymath}
    \Prob(\xi = k) = {(1-p)}^k p.
  \end{displaymath}
\end{definition}

Геометричното разпределение моделира номера на първия успешен опит сред безброй независими опити с еднаква вероятност $p$ или, при алтернативната дефиниция, броя неуспехи до появата на първия успех. То също е изключително приложимо, например за намирането на очаквания брой изтеглени игрални карти преди първия туз или за оценяване на необходимото количество допълнително произведени изделия, ако целим да произведем дадено количество изделия без дефект при вероятност за дефект $p$.

За пораждащата моментите функция, очакването и дисперсията на $\xi \in \DGeom(p)$ имаме
\begingroup
\allowdisplaybreaks
\begin{align*}
  \MGF_\xi(t)
  &=
  \Expect(e^{t\xi})
  =
  e^t p \sum_{k=1}^\infty {((1-p) e^t)}^{k-1}
  =
  e^t p \sum_{k=0}^\infty {((1-p) e^t)}^k
  = \\ &=
  \boxed{\frac {p e^t} {1 - (1-p) e^t}, (1-p) e^t < 1 \iff t < -\ln(1-p)},
  \\
  \MGF'_\xi(t)
  &=
  \frac {p e^t \cdot (1 - (1-p) e^t) + p e^t \cdot (1-p) e^t} {{(1 - (1-p) e^t)}^2}
  =
  \boxed{\frac {p e^t} {{(1 - (1-p) e^t)}^2}, t < -\ln(1-p)},
  \\
  \MGF''_\xi(t)
  &=
  \frac {p e^t \cdot {(1 - (1-p) e^t)}^2 + p e^t \cdot 2 (1 - (1-p) e^t) (1-p) e^t} {{(1 - (1-p) e^t)}^4}
  = \\ &=
  \frac {p e^t (1 - (1-p) e^t) (1 - (1-p) e^t + 2 (1-p) e^t)} {{(1 - (1-p) e^t)}^4}
  = \\ &=
  \boxed{\frac {p e^t (1 + e^t - p e^t)} {{(1 - (1-p) e^t)}^3}, t < -\ln(1-p)}
  \\
  \Expect(\xi)
  &=
  \frac p {p^2}
  =
  \boxed{\frac 1 p},
  \\
  \Expect(\xi^2)
  &=
  \frac {p(2-p)} {p^3}
  =
  \boxed{\frac {2-p} {p^2}},
  \\
  \Var(\xi)
  &=
  \frac {2-p} {p^2} - \frac 1 {p^2}
  =
  \boxed{\frac {1-p} {p^2}}.
\end{align*}
\endgroup

\begin{theorem}[Липса на памет]
  За $\xi \in \DGeom(p)$ и положителни цели числа $n$ и $m$ е изпълнено
  \begin{displaymath}
    \Prob(\xi = n + m \mid \xi > n) = \Prob(\xi = m)
  \end{displaymath}
\end{theorem}
\begin{proof}
  \begin{multline*}
    \Prob(\xi = n + m \mid \xi > n)
    =
    \frac {\Prob(\xi = n + m, \xi > n)} {\Prob(\xi > n)}
    =
    \frac {\Prob(\xi = n + m)} {\Prob(\xi > n)}
    =
    \frac {{(1-p)}^{n+m-1} p} {\sum_{k=n+1}^\infty {(1-p)}^{k-1} p}
    = \\ =
    \frac {{(1-p)}^{n+m-1} p} {{(1-p)}^n p \sum_{k=0}^\infty {(1-p)}^k}
    =
    \frac {{(1-p)}^{m-1}} {\frac 1 {1 - p}}
    =
    {(1-p)}^{m-1} p
    =
    \Prob(\xi = m).
  \end{multline*}
\end{proof}

\subsubsection{Поасоново разпределение}

\begin{definition}
  Казваме, че случайната величина $\xi$ има \underline{поасоново разпределение} с интензивност $\lambda \in \RPos$ и пишем $\xi \in \DPoisson(p)$, ако за всяко $k = 0, 2, \ldots$ е изпълнено
  \begin{displaymath}
    \Prob(\xi = k) = \frac{e^{-\lambda} \lambda^k} {k!}.
  \end{displaymath}

  Дефиницията е коректна, тъй като $\Prob(\xi = k) > 0$ за $k \in \ZNNeg$ и
  \begin{displaymath}
    \sum_{k=0}^\infty \Prob(\xi = k)
    =
    \sum_{k=0}^\infty \frac{e^{-\lambda} \lambda^k} {k!}
    =
    e^{-\lambda} e^{\lambda}
    =
    1.
  \end{displaymath}
\end{definition}

Ако дадено явление се случва със средна честота $\lambda$, поасоновото разпределение моделира количеството независими явления за единица време. Това го прави подходящо за широк спектър от задачи - от моделиране на броя посетители на магазин в натоварен час до моделиране на броя скокове в цените на финансов дериват.

За пораждащата моментите функция, очакването и дисперсията на $\xi \in \DPoisson(p)$ имаме
\begingroup
\allowdisplaybreaks
\begin{align*}
  \MGF_\xi(t)
  &=
  \Expect(e^{t\xi})
  =
  \sum_{k=0}^\infty \frac{e^{tk} e^{-\lambda} \lambda^k} {k!}
  =
  e^{-\lambda} \sum_{k=0}^\infty \frac{{(e^t \lambda)}^k} {k!}
  =
  e^{-\lambda} e^{e^t \lambda}
  =
  \boxed{e^{\lambda (e^t - 1)}},
  \\
  \MGF'_\xi(t)
  &=
  \lambda e^t e^{\lambda (e^t - 1)}
  =
  \boxed{\lambda e^{t + \lambda (e^t - 1)}},
  \\
  \MGF''_\xi(t)
  &=
  \lambda e^t \cdot e^{\lambda (e^t - 1)} + \lambda e^t \cdot \lambda e^t e^{\lambda (e^t - 1)}
  =
  \boxed{\lambda e^{t + \lambda (e^t - 1)} (1 + \lambda e^t)},
  \\
  \Expect(\xi)
  &=
  \boxed{\lambda},
  \\
  \Expect(\xi^2)
  &=
  \boxed{\lambda(1 + \lambda)},
  \\
  \Var(\xi)
  &=
  \lambda(1 + \lambda) - \lambda^2
  =
  \boxed{\lambda}.
\end{align*}
\endgroup

\begin{theorem}[Поасон]\label{thm:poisson}
  Нека $\xi_1, \xi_2, \ldots$ са независими и $\xi_k$ има разпределение $\DBinomial(k, p_k)$. Ако $k p_k \underset {k \to \infty} \longrightarrow \lambda$, тогава слабата граница $\lim_{k \to \infty} \xi_k$ съществува и има разпределение $\DPoisson(\lambda)$.
\end{theorem}

\section{Задачи}

\printbibliography

\end{document}
