% arara: pdflatex: { shell: true, interaction: nonstopmode }
% arara: biber
% arara: pdflatex: { shell: true }

\documentclass[numbers=endperiod, DIV=15, bibliography=totocnumbered]{scrartcl}

% Base packages
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}
\usepackage[pdfencoding=unicode]{hyperref}
\usepackage{biblatex}
\usepackage[style=german]{csquotes}

% Base math packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}

% Misc packages
\usepackage{enumitem} % Customization of enum counters
\usepackage{ulem} % Line-breaking underlines

% Custom packages
\usepackage{../../common/macros}
\usepackage{../../common/theorems}

% Bibliography
\addbibresource{./references.bib}

% Document
\title{Тема 16}
\subtitle{Случайни величини с непрекъснати разпределения. Нормално разпределение. Равномерно разпределение, експоненциално разпределение или гама разпределение. Задачи, в които възникват.}
\author{Янис Василев, \Email{ianis@ivasilev.net}}
\date{21 юни 2019}

\begin{document}

\maketitle

\section{Анотация}

Изложената анотацията е взета от конспекта~\cite{Syllabus} за 2018г.

\subsection{Теория}

\begin{enumerate}
  \item Дефиниция на непрекъснато разпределение на случайна величина
  \item Вероятностна плътност и свойствата ѝ - неотрицателност и нормираност
  \item Дефиниция на моментите на непрекъсната случайна величина
  \item Дефиниция и свойства (без доказателства) на пораждаща моментите/характеристична функция (по избор)
  \item Дефиниция, коректност, мотивиращ пример, пораждаща моментите/характеристична функция, очакване и дисперсия на нормално разпределение и още едно избрано от комисията непрекъснато разпределение
\end{enumerate}

\subsection{Задачи}

Не е даден списък с възможни задачи, затова съм включил разни задачи, давани на държавен изпит.

\section{Теория}

Теорията е представена с минимални препратки към теорията на мярката и е базирана частично на изложението в~\cite{Borovkov} и~\cite{DimitrovYanev}. За пълнота съм включил доказателства на основните свойства на пораждащи моментите и характеристична функции.

\subsection{Основни дефиниции и теореми}

\begin{definition}
  \uline{(Реална) случайна величина} над вероятностното пространство $(\Omega, \F, \Prob)$ наричаме всяка измерима функция $\xi : \Omega \to \R$.

  Условието за измеримост на $\xi$ може да се запише така: за всяко борелово множество $B \in \BorelAlgebra(\R)$ имаме
  \begin{displaymath}
    \xi^{-1} (B) = \{ \omega \in \Omega \mid \xi(\omega) \in B \} \in \F.
  \end{displaymath}

  \uline{Разпределение на $\xi$} наричаме мярката
  \begin{displaymath}
    \Prob_\xi(A) \coloneqq \Prob(\xi \in A).
  \end{displaymath}

  Две случайни величини $\xi$ и $\eta$ наричаме \uline{независими}, ако за всички $A, B \in \F$ е изпълнено
  \begin{displaymath}
    \Prob(\xi \in A, \eta \in B) = \Prob_\xi(A) \Prob_\eta(B).
  \end{displaymath}

  \uline{Функция на разпределение} на случайната величина $\xi$ наричаме
  \begin{displaymath}
    F_\xi(x) \coloneqq \Prob(\xi \leq x).
  \end{displaymath}

  Случайната величина $\xi$ наричаме \uline{абсолютно непрекъсната} и казваме, че $\xi$ има \uline{абсолютно непрекъснато разпределение}, ако функцията ѝ на разпределение е локално абсолютно непрекъсната в $\R$, т.е. абсолютно непрекъсната във всеки затворен интервал. Известно е, че абсолютно непрекъснатите в затворен интервал $[a, b]$ функции са точно тези, които са диференцируеми почти навсякъде в интервала, производните им в $[a, b]$ са интегруеми по Риман и за $x \in [a, b]$ е изпълнено
  \begin{displaymath}
    F_\xi(x) = \int_a^x F'_\xi(x) + F_\xi(a).
  \end{displaymath}

  Функцията $f_\xi: \R \mapsto \R$ наричаме \uline{вероятностна плътност} на случайната величина $\xi$, ако $F'_\xi(x) = f_\xi(x)$ във всяка точка, в която $F_\xi$ е диференцируема. Ако за едно разпределение съществуват множество плътности, те се различават само върху множество с лебегова мярка 0 и тъй като $f_\xi(x)$ се използва основно за интегриране, на практика няма значение с коя от плътностите ще работим.
\end{definition}

\begin{note}
  Абсолютно непрекъснатите случайни величини ще наричаме просто~\enquote{непрекъснати}. Понякога непрекъснати случайни величини се наричат такива с непрекъсната функция на разпределение, но това определение е прекалено общо и позволява т. нар. сингулярни разпределения, чиято плътност се анулира почти навсякъде.
\end{note}

\begin{proposition}[Основни свойства на функцията на разпределение]\label{thm:cdf-props}
  Функцията $F_\xi$ е функция на разпределение на някаква (не непременно абсолютно непрекъсната) случайна величина $\xi$ тогава и само тогава, когато са изпълнени
  \begin{enumerate}
    \item $F_\xi(x) \leq F_\xi(y), x < y$ (монотонност)
    \item $F_\xi(x)$ е непрекъсната отдясно
    \item $\lim_{x \downarrow -\infty} F_\xi(x) = 0$
    \item $\lim_{x \uparrow \infty} F_\xi(x) = 1$
  \end{enumerate}
\end{proposition}

Твърдение~\ref{thm:cdf-props} ни дава обосновка да задаваме случайни величини изцяло чрез функцията им на разпределение, т.е. без изрично да задаваме вероятностни пространства.

\begin{proof}[Доказателство на твърдение~\ref{thm:cdf-props}]
  ($\implies$)
  \begin{enumerate}
    \item За всички $x < y$
    \begin{multline*}
      F_\xi(x)
      =
      \Prob(\xi \leq x)
      =
      \Prob(\{ \omega \in \Omega \mid \xi(\omega) \leq x \})
      =
      \Prob(\{ \omega \in \Omega \mid \xi(\omega) \leq x \} \cap \{ \omega \in \Omega \mid \xi(\omega) \leq y \})
      \leq \\ \leq
      \Prob(\{ \omega \in \Omega \mid \xi(\omega) \leq y \})
      =
      \Prob(\xi \leq y)
      =
      F_\xi(y).
    \end{multline*}

    \item От монотонността на вероятностната мярка имаме
    \begin{multline*}
      \lim_{h \downarrow 0} F_\xi(x + h)
      =
      \lim_{h \downarrow 0} \Prob(\xi \leq x + h)
      =
      \lim_{h \downarrow 0} \Prob(\{ \omega \in \Omega \mid \xi(\omega) \leq x + h \})
      =
      \Prob(\cup_{h \geq 0} \{ \omega \in \Omega \mid \xi(\omega) \leq x + h \})
      = \\ =
      \Prob(\{ \omega \in \Omega \mid \xi(\omega) \leq x \})
      =
      \Prob(\xi \leq x)
      =
      F_\xi(x).
    \end{multline*}

    \item От монотонността на вероятностната мярка имаме
    \begin{multline*}
      \lim_{x \uparrow \infty} F_\xi(x)
      =
      \lim_{x \uparrow \infty} \Prob(\xi \leq x)
      =
      \lim_{x \uparrow \infty} \Prob(\{ \omega \in \Omega \mid \xi(\omega) \leq x \})
      =
      \Prob(\cup_{x \uparrow \infty} \{ \omega \in \Omega \mid \xi(\omega) \leq x \})
      = \\ =
      \Prob(\cup_{x \uparrow \infty} \{ \omega \in \Omega \mid \xi(\omega) \leq 1 \})
      =
      \Prob(\{ \omega \in \Omega \mid \xi(\omega) \leq \infty \})
      =
      \Prob(\Omega)
      =
      1.
    \end{multline*}

    \item $\lim_{x \uparrow \infty} F_\xi(x) = 0$ се доказва напълно аналогично на $\lim_{x \uparrow \infty} F_\xi(x) = 1$.
  \end{enumerate}

  ($\impliedby$) Нека функцията $F_\xi$ удовлетворява условията на теоремата. Дефинираме
  \begin{align*}
    \xi: \R \to \R,     &&& \Prob: \BorelAlgebra(\R) \to [0, 1], \\
    \xi(x) \coloneqq x, &&& \Prob((a, b]) \coloneqq F_\xi \left(\lim_{h \downarrow 0} b + h \right) - F_\xi(a), a < b \in \R.
  \end{align*}

  Интервалите от вида $(a, b]$ пораждат бореловата $\sigma$-алгебра $\BorelAlgebra(\R)$. Ще пропуснем доказателството на това, че $\Prob$ е вероятностна мярка над $(\R, \BorelAlgebra(\R))$.

  Тогава $\xi$ е измерима функция над $(\R, \BorelAlgebra(\R), \Prob)$ и освен това
  \begin{displaymath}
    \Prob(\xi \leq x)
    =
    \Prob((-\infty, x])
    =
    F_\xi(x)~\forall x \in \R.
  \end{displaymath}

  С други думи, построихме вероятностно пространство и случайна величина $\xi$, чиято функцията на разпределение е $F_\xi$.
\end{proof}

До края на темата ще считаме, че работим над вероятностното пространство $(\Omega, \F, \Prob)$.

\begin{theorem}\label{thm:density-props}
  Интегруемата по Риман функция $f_\xi: \R \to \R$ е плътност на някаква абсолютно непрекъсната случайна величина $\xi$ тогава и само тогава, когато са изпълнени
  \begin{enumerate}
    \item $f_\xi(x) \geq 0$ почти навсякъде (неотрицателност)
    \item $\int_\R f_\xi(x) dx = 1$ (нормираност)
  \end{enumerate}
\end{theorem}

Тази теорема ни позволява да задаваме непрекъсната случайна величина изцяло чрез плътността ѝ, поради което плътността понякога се нарича разпределение на случайната величина.

\begin{proof}[Доказателство на теорема~\ref{thm:density-props}]
  ($\implies$) Нека $f_\xi$ е плътност на $\xi$.
  \begin{enumerate}
    \item За всяка точка $x \in \R$, в която $F_\xi$ е диференцируема, имаме $f_\xi(x) = F'_\xi(x) = \lim_{h \downarrow 0} \frac {F_\xi(x + h) - F_\xi(x)} h \geq 0$ поради монотонността на $F_\xi$
    \item За произволно $c > 0$ функцията $F_\xi$ е абсолютно непрекъсната в $[-c, c]$. Следователно
    \begin{displaymath}
      \int_\R f_\xi(x) dx
      =
      \lim_{c \uparrow \infty} \int_{-c}^c f_\xi(x) dx
      =
      \lim_{c \uparrow \infty} F_\xi(c) - \lim_{c \to \infty} F_\xi(-c)
      =
      1 - 0.
    \end{displaymath}
  \end{enumerate}

  ($\impliedby$) Нека $f_\xi: \R \to \R$ е неотрицателна, интегруема по Риман и нормирана. Дефинираме функцията $F_\xi(x) \coloneqq \int_{-\infty}^x f_\xi(t) dt$. Ще покажем, че за $F_\xi$ са изпълнени свойствата на функция на разпределение:
  \begin{enumerate}
    \item Ако $x < y$, от адитивността на римановия интеграл и неотрицателността на $f_\xi$ следва
    \begin{displaymath}
      F_\xi(x)
      =
      \int_{-\infty}^x f_\xi(t) dt
      \leq
      \int_{-\infty}^x f_\xi(t) dt + \int_x^y f_\xi(t) dt
      =
      \int_{-\infty}^y f_\xi(t) dt
      =
      F_\xi(y).
    \end{displaymath}

    \item $F_\xi$ е непрекъсната отдясно, тъй като
    \begin{displaymath}
      \lim_{h \downarrow 0} F_\xi(x + h)
      =
      \lim_{h \downarrow 0} \int_{-\infty}^{x + h} f_\xi(t) dt
      =
      \int_{-\infty}^x f_\xi(t) dt + \lim_{h \downarrow 0} \int_x^{x + h} f_\xi(t) dt
      =
      \int_{-\infty}^x f_\xi(t) dt
      =
      F_\xi(x).
    \end{displaymath}

    \item От предположението за нормираност имаме
    \begin{displaymath}
      \lim_{x \uparrow \infty} F_\xi(x)
      =
      \lim_{x \uparrow \infty} \int_{-\infty}^x f_\xi(x) dx
      =
      \int_\R f_\xi(x) dx = 1.
    \end{displaymath}

    \item Директно пресмятаме
    \begin{displaymath}
      \lim_{x \downarrow -\infty} \int_{-\infty}^x f_\xi(x) dx
      =
      \int_{-\infty}^{-\infty} f_\xi(x) dx
      =
      0.
    \end{displaymath}
  \end{enumerate}

  Видяхме, че $F_\xi$ удовлетворява свойствата на функция на разпределение и по~\ref{thm:cdf-props} съществува случайна величина $\xi$, чиято плътност е $f_\xi$.

  Освен това $F_\xi$ е абсолютно непрекъсната във всеки затворен интервал $[a, b]$, тъй като тя има интегруема производна почти навсякъде и за $x \in [a, b]$ е изпълнено
  \begin{displaymath}
    F_\xi(x)
    =
    \int_{-\infty}^x f_\xi(x) dx
    =
    \int_{-\infty}^a f_\xi(x) dx + \int_a^x f_\xi(x) dx
    =
    F_\xi(a) + \int_a^x f_\xi(x) dx.
  \end{displaymath}
\end{proof}

\begin{proposition}[Конволюция на плътности]\label{thm:convolution}
  Сумата на две независими непрекъснати случайни величини $\xi$ и $\eta$ е непрекъсната случайна величина с плътност
  \begin{displaymath}
    f_{\xi + \eta} (x)
    =
    \int_\R f_\xi(t) f_\eta(x - t) dt
    =
    \int_\R f_\xi(t) f_\eta(x - t) dt.
  \end{displaymath}
\end{proposition}
\begin{proof} От формулата за пълната вероятност и независимостта на $\xi$ и $\eta$ имаме
  \begin{displaymath}
    F_{\xi + \eta} (x)
    =
    \Prob(\xi + \eta \leq x)
    =
    \Prob(\xi \leq x - \eta)
    =
    \int_\R \Prob(\xi \leq x - t) f_\eta(t) dt
    =
    \int_\R F_\xi(x - t) f_\eta(t) dt.
  \end{displaymath}

  Аналогично се доказва
  \begin{displaymath}
    f_{\xi + \eta} (x)
    =
    \int_\R f_\xi(t) f_\eta(x - t) dt.
  \end{displaymath}
\end{proof}

\begin{proposition}\label{thm:transformation-density}
  Ако $\xi$ е случайна величина и функцията $\psi: \R \to \R$ е строго монотонна и диференцируема, тогава $\psi(\xi)$ е непрекъсната случайна величина с плътност
  \begin{displaymath}
    f_{\psi(\xi)} (x)
    =
    \Abs{(\psi^{-1})'(x)} f(\psi^{-1}(x)).
  \end{displaymath}
\end{proposition}
\begin{proof} Диференцирайки $F_{\psi(\xi)} = \Prob(\psi(\xi) \leq x) = \Prob(\xi \leq \psi^{-1}(x)) = F_\xi(\psi^{-1}(x))$ по $x$ получаваме
  \begin{displaymath}
    f_{\psi(\xi)} (x)
    =
    F'_{\psi(\xi)} (x)
    =
    (F_{\xi} \circ \psi^{-1})'(x)
    =
    \Abs{(\psi^{-1})'(x)} f(\psi^{-1}(x)).
  \end{displaymath}
\end{proof}

\subsection{Очакване и моменти}

\begin{definition}
  Нека $\xi$ е непрекъсната случайна величина. Дефинираме \uline{очакване на $\xi$} чрез
  \begin{displaymath}
    \Expect(\xi) \coloneqq \int_\R x f_\xi(x) dx.
  \end{displaymath}
  Казваме, че $\xi$ има (крайно) очакване, ако интегралът е абсолютно сходящ, т.е. $\Abs{x f_\xi}$ е интегруема функция.

  Случайни величини с очакване нула наричаме \uline{центрирани}.

  Очакване от константа $x \in \R$ дефинираме да бъде самата константа $x$.
\end{definition}

\begin{note}
  Очакването се дефинира за произволна случайна величина $\xi$ се дефинира чрез интеграл по вероятностната мярка, т.е.
  \begin{displaymath}
    \Expect(\xi) \coloneqq \int \xi d\Prob.
  \end{displaymath}

  Нещо повече, очакването е линеен функционал над линейното пространството от всички случайни величини над $(\Omega, \F, \Prob)$.

  Непрекъснатите случайни величини обаче не образуват линейно подпространство, тъй като сумата на две зависими непрекъснати случайни величини може да не бъде непрекъсната (например $\xi - \xi = 0$). Тъй като тук се ограничаваме само до непрекъснати случайни величини, ще формулираме някои свойства (например адитивност) само в частния случай, в който случайните величини са независими.
\end{note}

\begin{proposition}\label{thm:expect-product}
  За независими непрекъснати случайни величини $\xi$ и $\eta$ с крайно очакване е изпълнено
  \begin{displaymath}
    \Expect(\xi \eta) = \Expect(\xi) \Expect(\eta).
  \end{displaymath}
\end{proposition}
\begin{proof}
  Прилагаме теоремата на Фубини, теоремата за средните стойности и формулата за пълната вероятност:
  \begin{multline*}
    \Expect(\xi \eta)
    =
    \int_\R z f_{\xi \eta}(z) dz
    =
    \int_\R z \Prob(z \leq \xi \eta < z + dz) dz
    =
    \int_\R \int_\R z \Prob(z \leq t \xi < z + dz) f_\eta(t) dz
    = \\ =
    \int_\R \int_\R z \left( F_\xi\left(\frac z t \right) - F_\xi\left(\frac z t + d\frac z t \right) \right) f_\eta(t) dt \; dz
    =
    \int_\R \int_\R z f_\xi \left(\frac z t \right) f_\eta(t) dt \; dz
    = \\ =
    \int_\R t f_\eta(t) \left(\int_\R \frac z t f_\xi \left(\frac z t \right) d\frac z t \right) dt
    =
    \Expect(\xi) \int_\R t f_\eta(t) dt
    =
    \Expect(\xi) \Expect(\eta).
  \end{multline*}
\end{proof}

\begin{proposition}\label{thm:expect-additive}
  Ако $\xi$ и $\eta$ са непрекъснати и независими, имаме $\Expect(\xi + \eta) = \Expect(\xi) + \Expect(\eta)$.
\end{proposition}
\begin{proof}
  От твърдение~\ref{thm:convolution} знаем, че $\xi + \eta$ също има непрекъснато разпределение и плътността ѝ е конволюция на плътностите на $\xi$ и $\eta$. Тогава от теоремата на Фубини имаме
  \begin{multline*}
    \Expect(\xi + \eta)
    =
    \int_\R x f_{\xi + \eta} (x) dx
    =
    \int_\R x \int_\R f_\xi(x - t) f_\eta(t) dt \; dx
    =
    \int_\R \left( \int_\R x f_\xi(x - t) dx \right) f_\eta(t) dt
    = \\ =
    \int_\R \left( \int_\R (x - t + t) f_\xi(x - t) d(x - t) \right) f_\eta(t) dt
    = \\ =
    \int_\R \left( \int_\R (x - t) f_\xi(x - t) d(x - t) + t \int_\R f_\xi(x - t) d(x - t) \right) f_\eta(t) dt
    = \\ =
    \int_\R (\Expect(\xi) + t) f_\eta(t) dt
    =
    \Expect(\xi) \int_\R f_\eta(t) dt + \int_\R t f_\eta(t) dt
    =
    \Expect(\xi) + \Expect(\eta).
  \end{multline*}
\end{proof}

\begin{proposition}\label{thm:lotus}
  Нека $\xi$ е непрекъсната случайна величина с крайно очакване. Нека $\psi: \R \to \R$ е монотонна. Тогава $\psi(\xi)$ е непрекъсната случайна и е изпълнено
  \begin{displaymath}
    \Expect(\psi(\xi))
    =
    \int_\R \psi(x) f_\xi(x) dx.
  \end{displaymath}
\end{proposition}

\begin{proof}
  \begin{multline*}
    \Expect(\psi(\xi))
    =
    \int_\R x f_{\psi(\xi)}(x) dx
    =
    \int_\R x \Prob(x \leq \psi(\xi) \leq x + dx) dx
    = \\ =
    \int_\R x \Prob(\psi^{-1}(x) \leq \xi \leq \psi^{-1}(x + dx)) dx
    =
    \int_\R x \left( F_\xi(\psi^{-1}(x + dx)) - F_\xi(\psi^{-1}(x)) \right) dx
    = \\ =
    \int_\R x f_\xi(\psi^{-1}(x)) dx
    =
    \int_\R \psi(x) f_\xi(x) d \psi(x)
    =
    \int_\R \psi(x) f_\xi(x) \psi'(x) dx.
  \end{multline*}
\end{proof}

Доказаните в твърдения~\ref{thm:expect-product},~\ref{thm:expect-additive} и~\ref{thm:lotus} свойства на очакването значително опростяват работата с него.

\begin{definition}
  \uline{Ковариация на случайните величини $\xi$ и $\eta$} наричаме
  \begin{displaymath}
    \Cov(\xi, \eta)
    \coloneqq
    \Expect((\xi - \Expect \xi) (\eta - \Expect \eta)).
  \end{displaymath}

  \uline{Дисперсия или вариация на случайната величина $\xi$} наричаме
  \begin{displaymath}
    \Var(\xi)
    \coloneqq
    \Cov(\xi, \xi)
    =
    \Expect \left({(\xi - \Expect \xi)}^2 \right)
    =
    \Expect(\xi^2 - 2 \xi \Expect \xi + {\Expect(\xi)}^2)
    =
    \Expect(\xi^2) - 2 {\Expect(\xi)}^2 + {\Expect(\xi)}^2
    =
    \Expect(\xi^2) - {\Expect(\xi)}^2.
  \end{displaymath}

  Числото $\Expect(\xi^n)$ наричаме \uline{$n$-ти момент на $\xi$}, а $\Expect \left( {(\xi - \Expect \xi)}^n \right)$ наричаме \uline{$n$-ти централен момент на $\xi$}.

  Очакването всъщност е просто първият момент, а дисперсията - вторият централен момент. Коренът на дисперсията се нарича \uline{стандартно отклонение} и често се бележи със $\sigma_\xi$.

  Две случайни величини се наричат \uline{ортогонални}, ако ковариацията им е $0$, защото ковариацията играе ролята на скаларно произведение в пространството $\LSpace^2$ от (всички, не непременно непрекъснати) случайни величини с краен втори момент.

  Случайни величини със стандартно отклонение единица наричаме \uline{нормирани}, тъй като стандартно отклонение играе ролята на норма в $\LSpace^2$.
\end{definition}

\begin{proposition}\label{thm:orthogonal-if-independent}
  Ако две случайни величини са независими и имат крайно очакване, те са ортогонални.
\end{proposition}
\begin{proof}
  Нека $\xi$ и $\eta$ са независими и имат крайни очаквания съответно $\mu$ и $\eta$. Тогава
  \begin{displaymath}
    \Cov(\xi, \eta)
    =
    \Expect((\xi - \mu) (\eta - \nu))
    =
    \Expect(\xi - \mu) \Expect(\eta - \nu)
    =
    (\mu - \mu) (\nu - \nu)
    =
    0 \cdot 0
    =
    0.
  \end{displaymath}
\end{proof}

\begin{proposition}\label{thm:lower-order-moments}
  Ако $\Expect(\xi^n)$ съществува, съществуват и моментите от по-нисък ред.
\end{proposition}
\begin{proof}
  Първо да забележим, че за $y \in (0, 1)$ имаме ${\Prob(\xi \leq x)}^y < \Prob(\xi \leq x)$. Ще докажем, че $\Expect({\Abs{\xi}}^{n-1})$ съществува. Прилагаме неравенството на Йенсен за риманови интеграли:
  \begin{multline*}
    \Expect({\Abs{\xi}}^{n-1})
    \leq
    {\Expect({\Abs{\xi}}^{n-1})}^{\frac n {n-1}}
    =
    {\left( \int_\R {\Abs{x_k}}^{n-1} f_\xi(x) \right)}^{\frac n {n-1}}
    \leq
    \int_\R {\left({\Abs{x_k}}^{n-1} f_\xi(x) \right)}^{\frac n {n-1}}
    < \\ <
    \int_\R {\left({\Abs{x_k}}^{n-1}\right)}^{\frac n {n-1}} f_\xi(x)
    =
    \int_\R {\Abs{x_k}}^n f_\xi(x)
    =
    \Expect({\Abs{\xi}}^n).
  \end{multline*}
\end{proof}

\begin{definition}
  Ако една случайна величина има крайна дисперсия, можем да я~\uline{стандартизираме}, разглеждайки вместо нея
  \begin{displaymath}
    \overline \xi = \frac {\xi - \Expect(\xi)} {\sqrt{\Var(\xi)}}.
  \end{displaymath}
\end{definition}

\begin{proposition}
  Стандартизираните случайни величини са винаги центрирани и нормирани.
\end{proposition}
\begin{proof}
  Ако $\xi$ е произволна случайна величина с крайна дисперсия, имаме
  \begin{align*}
    \Expect(\overline \xi)
    &=
    \frac 1 {\sqrt{\Var(\xi)}} \Expect(\xi - \Expect\xi)
    =
    0
    \\
    \Var(\overline \xi)
    &=
    \frac 1 {\Var(\xi)} \Expect({\left[ \xi - \Expect\xi - \Expect(\xi - \Expect\xi) \right]}^2) = 0
    =
    \frac 1 {\Var(\xi)} \Expect({(\xi - \Expect\xi)}^2)
    =
    \frac {\Var(\xi)} {\Var(\xi)}
    =
    1.
  \end{align*}
\end{proof}

\subsection{Пораждащи моментите и характеристични функции}

\begin{definition}
  \uline{Пораждаща моментите функция на $\xi$} наричаме
  \begin{displaymath}
    \MGF_\xi (t) \coloneqq \Expect(e^{t\xi}).
  \end{displaymath}

  \uline{Характеристична функция на $\xi$} наричаме
  \begin{displaymath}
    \Char_\xi (t) \coloneqq \Expect(e^{it\xi}).
  \end{displaymath}

  Изпълнено е $\Char_\xi(t) = \MGF_\xi(it)$.
\end{definition}

\begin{note}
  Не сме дефинирали очакване от комплексна случайна величина, но теоретичната обосновка идва от формулите на Ойлер:
  \begin{displaymath}
    \Char_\xi (t)
    =
    \Expect(e^{it\xi})
    =
    \Expect(\cos(t\xi) + i\sin(t\xi))
    =
    \Expect(\cos(t\xi)) + i \Expect(\sin(t\xi)).
  \end{displaymath}
\end{note}

\begin{note}
  Дефинициите за моменти и функции от очакването се пренасят без изменение за случайни величини, които не са непрекъснати.
\end{note}

\begin{theorem}[Свойства на пораждащите моментите функции]\label{thm:mgf-props}
  Нека $\xi$ и $\eta$ са независими непрекъснати случайни величини.

  За пораждащите моментите функции $\MGF_\xi$ и $\MGF_\eta$ са изпълнени следните свойства
  \begin{enumerate}
    \item В общия случай пораждащата моментите функция съществува само в $0$. Ако тя съществува в околност на $0$, то тя е гладка в тази околност, съществуват всички моменти и е изпълнено $\Expect(\xi^m) = \MGF_\xi^{(m)} (0)$ за $m = 1, 2, \ldots$.

    \item Ако пораждащите моментите функции на $\xi$, $\eta$ и $\xi + \eta$ съществуват в точка $t \in \R$, имаме
    \begin{displaymath}
      \MGF_{\xi + \eta}(t) = \MGF_\xi(t) \MGF_\eta(t).
    \end{displaymath}

    \item Ако $\MGF_\xi$ и $\MGF_\eta$ имат обща дефиниционна област, различна от $\{ 0 \}$, в която те съвпадат, то $\xi$ и $\eta$ имат еднакво разпределение.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \mbox{}
  \begin{enumerate}
    \item Пораждащата моментите функция винаги съществува в $0$, тъй като $\MGF_\xi(0) = \Expect(e^{0\xi}) = \Expect(1) = 1$.

    Нека $\MGF_\xi$ съществува в околност $U$ на $0$. Без ограничение на общността ще считаме, че $U$ е ограничена. Полагаме $\tau \coloneqq \min(-\inf U, \sup_U)$. Тогава сумата $\MGF_\xi(-\tau) + \MGF_\xi(\tau)$ е крайна. Развиваме тази сума в ред на Тейлър:
    \begin{displaymath}
      \MGF_\xi(-\tau) + \MGF_\xi(\tau)
      =
      \Expect(e^{-\tau\xi} + e^{\tau\xi})
      =
      \Expect\left( 2 \sum_{k=0}^\infty \frac {\xi^{2k}} {(2k)!} \tau^{2k} \right)
      =
      2 \sum_{k=0}^\infty \frac {\Expect(\xi^{2k})} {(2k)!} \tau^{2k}.
    \end{displaymath}

    Внасянето на очакването е възможно, защото всички членове на реда са неотрицателни. От $\Expect(\xi^{2m}) = \Expect(\Abs{\xi^{2m}})$ се вижда, че всички четни моменти съществуват. Според твърдение~\ref{thm:lower-order-moments} съществуват и всички нечетни моменти.

    Остава да докажем, че са налице условията за $m$-кратно почленно диференциране на реда $\Char_\xi(t) = \Expect (e^{t\xi})$ в областта $\frac 1 {2^m} U = \{ \frac t {2^m} U \mid t \in U \}$.

    Разглеждаме очакването на $m$-тата производна $\xi^m e^{t \xi}$ на $e^{t \xi}$ по $t$. Налице са условията за диференциране под знака на интеграла:
    \begin{enumerate}
      \item За $m > 0$ прилагаме неравенството на Коши-Буняковски-Шварц, за да докажем, че $\Expect \left( \xi^m e^{t \xi} \right)$ съществува за $t \in \frac 1 {2^m} U$:
      \begin{multline*}
        {\left(\Expect \left( \xi^m e^{t \xi} \right) \right)}^2
        =
        {\left(\int_\R x^m e^{t x} f_\xi(x) \right)}^2
        = \\ =
        {\left(\int_\R \left(x^m \sqrt{f_\xi(x)} \right) \left(e^{t x} \sqrt{f_\xi(x)} \right) dx \right)}^2
        \leq \\ \leq
        \int_\R x^{2m} f_\xi(x) dx
        \int_\R e^{2tx} f_\xi(x) dx
        = \\ =
        \Expect(\xi^{2m})
        \Expect(e^{2t \xi})
        =
        \Expect(\xi^{2m})
        \MGF_\xi(2t).
      \end{multline*}

      \item Функцията $x \mapsto x^m e^{t x}$ е диференцируема по $t$ за всяко $x \in \R$.
      \item Производната на $x^m e^{t x}$ по $t$ се мажорира по абсолютна стойност от
      \begin{displaymath}
        \Abs{x^{m+1} e^{t x}}
        \leq
        {\Abs{x}}^{m+1} \Abs{e^{t x}}
        \leq
        {\Abs{x}}^{m+1} e^{\Abs{t x}}
        \leq
        {\Abs{x}}^{m+1} e^{\tau \Abs{x}},
      \end{displaymath}
      където мажорантата не зависи от $t$.
    \end{enumerate}

    По индукция за $m = 1, 2, \ldots$ получаваме $\MGF^{(m)}_\xi(t) = i^m \Expect(\xi^m e^{t \xi})$ в $\frac 1 {2^m} U$. В частност, $\MGF^{(m)}_\xi(0) = \Expect(\xi^m e^{0 \xi}) = \Expect(\xi^m)$.

    \item Ако пораждащите моментите функции съществуват в $t \in \R$, тъй като $\xi$ и $\eta$ са независими, случайните величини $e^{t\xi}$ и $e^{t\eta}$ също са независими и
    \begin{displaymath}
      \MGF_{\xi + \eta}(t)
      =
      \Expect(e^{t(\xi + \eta)})
      =
      \Expect(e^{t\xi} e^{t\eta})
      =
      \Expect(e^{t\xi}) \Expect(e^{t\eta})
      =
      \MGF_\xi(t) \MGF_\eta(t).
    \end{displaymath}

    \item Ако функциите $\MGF_\xi$ и $\MGF_\eta$ съвпадат в областта си на дефиниция $U$, за $t \in U$ имаме
    \begin{align*}
      \MGF_\xi(t) - \MGF_\eta(t) &= 0
      \\
      \int_\R e^{tx} f_\xi(x) - \int_\R e^{tx} f_\eta(x) dx &= 0
      \\
      \int_\R e^{tx} (f_\xi(x) - f_\eta(x)) dx &= 0.
    \end{align*}
    Последното равенство е изпълнено за всяко $t \in U$ точно когато $f_\xi(x) = f_\eta(x)$ почти за всяко $x \in \R$. Следователно $\xi$ и $\eta$ имат еднакво разпределение.
  \end{enumerate}
\end{proof}

\begin{theorem}[Свойства на характеристичните функции]\label{thm:char-props}
  Нека $\xi$ и $\eta$ са независими дискретни случайни величини.

  За характеристичните функции $\Char_\xi$ и $\Char_\eta$ са изпълнени следните свойства
  \begin{enumerate}
    \item $\Char_\xi$ съществува и е равномерно непрекъсната навсякъде върху реалната права.

    \item Ако $\xi^n$ има краен $n$-ти момент, е изпълнено $\Expect(\xi^m) = i^{-m} \Char_\xi^{(m)} (0)$ за $m = 1, \ldots, n$.

    \item За всяко $t \in \R$ имаме
    \begin{displaymath}
      \Char_{\xi + \eta}(t) = \Char_\xi(t) \Char_\eta(t).
    \end{displaymath}

    \item Ако $\Char_\xi$ и $\Char_\eta$ съвпадат, то $\xi$ и $\eta$ имат еднакво разпределение.
  \end{enumerate}
\end{theorem}
\begin{proof}
  \mbox{}
  \begin{enumerate}
    \item За да докажем, че $\Char_\xi$ е дефинирана навсякъде в $\R$, оценяваме отгоре абсолютната стойност на $\Char_\xi$ за $t \in \R$:
    \begin{displaymath}
      \Abs{\Char_\xi(t)}
      =
      \Abs{\Expect(e^{it\xi})}
      =
      \Abs{\int_\R e^{itx} f_\xi(x) dx}
      \leq
      \int_\R \Abs{e^{itx}} f_\xi(x) dx
      =
      \int_\R f_\xi(x) dx
      =
      1.
    \end{displaymath}

    За да докажем и равномерната непрекъснатост в $\R$, първо оценяваме отгоре израза
    \begin{multline*}
      \Abs{\Char_\xi(t + h) - \Char_\xi(t)}
      =
      \Abs{\Expect(e^{i(t + h)\xi}) - \Expect(e^{it\xi})}
      = \\ =
      \Abs{\Expect(e^{it\xi} (e^{ih\xi} - 1))}
      =
      \Abs{\int_\R e^{itx} (e^{ihx} - 1) f_\xi(x) dx}
      \leq \\ \leq
      \int_\R \Abs{e^{itx}} \Abs{(e^{ihx} - 1)} f_\xi(x) dx
      =
      \int_\R \Abs{(e^{ihx} - 1)} f_\xi(x) dx.
    \end{multline*}

    Ще използваме, че за всяко $z \in \Complex$ неравенството на Йенсен ни дава
    \begin{displaymath}
      \Abs{e^{iz} - 1}
      =
      \Abs{i \int_0^z e^{it} dt}
      \leq
      \int_0^{\Abs{z}} \Abs{e^{it}} dt
      =
      \int_0^{\Abs{z}} dt
      =
      \Abs{z}.
    \end{displaymath}

    Фиксираме $\varepsilon > 0$. Избираме константа $c_\varepsilon > 0$ такава, че $\Prob(\Abs{\xi} > c_\varepsilon) < \frac \varepsilon 3$.
    Разглеждаме две множества: $A \coloneqq (-c_\varepsilon, c_\varepsilon)$ и $B \coloneqq \R \setminus A$.

    За $x \in A$ имаме
    \begin{displaymath}
      \int_A \Abs{e^{ihx} - 1} f_\xi(x) dx
      \leq
      \int_A \Abs{h x} f_\xi(x) dx
      \leq
      c_\varepsilon \Abs h \int_A f_\xi(x) dx
      \leq
      c_\varepsilon \Abs h.
    \end{displaymath}

    За $x \in B$ имаме
    \begin{displaymath}
      \int_B \Abs{e^{ihx} - 1} f_\xi(x) dx
      \leq
      \int_B \left( \Abs{e^{ihx}} + 1 \right) f_\xi(x) dx
      \leq
      2 \int_B f_\xi(x) dx
      <
      \frac {2\varepsilon} 3.
    \end{displaymath}

    За целия интеграл тогава получаваме
    \begin{displaymath}
      \int_\R \Abs{e^{ihx} - 1} f_\xi(x) dx
      <
      c_\varepsilon \Abs{h} + 2 \varepsilon.
    \end{displaymath}

    Полагаме $\delta = \frac \varepsilon {3 c_\varepsilon}$.

    Тогава за $\Abs h < \delta$ имаме
    \begin{displaymath}
      \Abs{\Char_\xi(t + h) - \Char_\xi(t)}
      <
      c_\varepsilon \Abs{h} + \frac {2\varepsilon} 3
      <
      \frac {\varepsilon} 3 + \frac {2\varepsilon} 3
      =
      \varepsilon.
    \end{displaymath}

    Числото $\delta$ зависи само от $\varepsilon$, следователно $\Char_\xi(t)$ е равномерно непрекъсната върху цялата реална права.

    \item Нека съществува моментът $\Expect \xi^n$. Тогава съществуват и моментите от по-нисък ред.

    Ще докажем, че са налице условията за $m$-кратно почленно диференциране на реда $\Char_\xi(t) = \Expect (e^{it \xi})$.

    Разглеждаме очакването на $m$-тата производна $i^m \xi^m e^{it \xi}$ на $e^{it \xi}$ по $t$. Налице са условията за диференциране под знака на интеграла:
    \begin{enumerate}
      \item $\Expect \left( i^m \xi^m e^{it \xi} \right)$ съществува за $t \in \R$, тъй като
      \begin{multline*}
        \Abs{\Expect \left( i^m \xi^m e^{it \xi} \right)}
        =
        \Abs{\Expect \left( \xi^m e^{it \xi} \right)}
        =
        \Abs{\int_\R x^m e^{itx} f_\xi(x) dx}
        \leq
        \int_\R \Abs{x^m e^{itx} f_\xi(x)} dx
        = \\ =
        \int_\R \Abs{x^m} \Abs{e^{itx}} f_\xi(x) dx
        =
        \int_\R \Abs{x^m} f_\xi(x) dx
        =
        \Expect \left( {\Abs{\xi^m}} \right).
      \end{multline*}
      Последното очакване е крайно, тъй като $\Expect(\Abs{\xi^0}) = 1$, а за $m > 0$ по условие интегралът $\Expect(\xi^m)$ е абсолютно сходящ.
      \item Функцията $x \mapsto i^m x^m e^{it x}$ е диференцируема по $t$ за всяко $x \in \Image(\xi)$.
      \item Производната на $i^m x^m e^{it x}$ по $t$ се мажорира по абсолютна стойност от $\Abs{x^{m+1} e^{it x}} \leq {\Abs{x}}^{m+1}$, където мажорантата не зависи от $t$.
    \end{enumerate}

    По индукция за $m = 1, \ldots, n$ получаваме $\Char^{(m)}_\xi(t) = i^m \Expect(\xi^m e^{t \xi})$. В частност, $\Char^{(m)}_\xi(0) = i^m \Expect(\xi^m e^{0 \xi}) = i^m \Expect(\xi^m)$.

    \item Тъй като $\xi$ и $\eta$ са независими, за произволно $t \in \R$ величините $e^{t\xi}$ и $e^{t\eta}$ са независими и
    \begin{displaymath}
      \Char_{\xi + \eta}(t)
      =
      \Expect(e^{it(\xi + \eta)})
      =
      \Expect(e^{it\xi} e^{it\eta})
      =
      \Expect(e^{it\xi}) \Expect(e^{it\eta})
      =
      \Char_\xi(t) \Char_\eta(t).
    \end{displaymath}

    \item Ако функциите $\MGF_\xi$ и $\MGF_\eta$ съвпадат, имаме
    \begin{align*}
      \Char_\xi(t) - \Char_\eta(t) &= 0
      \\
      \int_\R e^{itx} f_\xi(x) - \int_\R e^{itx} f_\eta(x) dx &= 0
      \\
      \int_\R e^{itx} (f_\xi(x) - f_\eta(x)) dx &= 0.
    \end{align*}
    Последното равенство е изпълнено за всяко $t \in \R$ точно когато $f_\xi(x) = f_\eta(x)$ почти за всяко $x \in \R$. Следователно $\xi$ и $\eta$ имат еднакво разпределение.
  \end{enumerate}
\end{proof}

\subsection{Често срещани непрекъснати разпределения}

\subsubsection{Нормално разпределение}\label{dist:normal}

\begin{definition}
  Казваме, че случайната величина $\xi$ има \uline{нормално разпределение} с очакване $\mu \in \R$ и стандартно отклонение $\sigma > 0$ и пишем $\xi \in \DNormal(\mu, \sigma^2)$, ако плътността има вида
  \begin{displaymath}
    f_\xi(x) = \frac 1 {\sqrt{2\pi} \sigma} e^{-\frac{{(x-\mu)}^2} {2\sigma^2}}.
  \end{displaymath}

  Дефиницията на плътност е коректна, тъй като $f_\xi(x) \geq 0~\forall x \in \R$ и от $\int_\R e^{-x^2} dx = \sqrt \pi$ получаваме
  \begin{displaymath}
    \int_\R \varphi(x) dx
    =
    \int_\R \frac 1 {\sqrt{2\pi} \sigma} e^{-\frac{{(x-\mu)}^2} {2\sigma^2}} dx
    =
    \frac 1 {\sqrt{\pi}} \int_\R e^{-{\left(\frac {x-\mu} {\sqrt 2 \sigma} \right)}^2} d\left(\frac {x-\mu} {\sqrt 2 \sigma} \right)
    =
    \frac {\sqrt{\pi}} {\sqrt{\pi}}
    =
    1.
  \end{displaymath}

  Разпределението на $\xi$ наричаме \uline{стандартно нормално}, ако $\mu = 0$ и $\sigma = 1$. Обикновено плътността и функцията на разпределение на стандартното нормално разпределение се бележат съответно с $\varphi(x)$ и $\Phi(x)$.
\end{definition}

Поради различните варианти на централната гранична теорема, нормалното разпределение е гранично за средно аритметичното на независими случайни величини от много други разпределения. Това го прави най-широко приложимото вероятностно разпределение. На практика нормалното разпределение се използва за приближено описание на всякакъв род данни - от анализ на резултати от социологически проучвания до моделиране на финансови пазари или термална радиация.

Нека $\eta \in \DNormal(\mu, \sigma^2)$ и $\xi \coloneqq \frac {\xi - \mu} \sigma$. Тъй като $\eta = \sigma \xi + \mu$, от твърдение~\ref{thm:transformation-density} получаваме, че плътността на $\xi$ е
\begin{displaymath}
  f_\xi(x)
  =
  \sigma \cdot f_\eta(\sigma x + \mu)
  =
  \sigma \cdot \frac 1 {\sqrt{2\pi} \sigma} e^{-\frac{{(\sigma x + \mu -\mu)}^2} {2\sigma^2}}
  =
  \frac 1 {\sqrt{2\pi}} e^{-\frac {x^2} 2}
  =
  \varphi(x).
\end{displaymath}

Получихме, че $\xi \in \DNormal(0, 1)$ има стандартно нормално разпределение. Затова е достатъчно да намерим пораждащата моментите функция, очакването и дисперсията само на стандартното нормално разпределение:
\begingroup
\allowdisplaybreaks
\begin{align*}
  \MGF_\xi(t)
  &=
  \Expect(e^{t\xi})
  =
  \int_\R e^{tx} \cdot \frac 1 {\sqrt{2\pi}} e^{-\frac {x^2} 2} dx
  =
  \frac 1 {\sqrt{2\pi}} \int_\R e^{tx -\frac {x^2} 2} dx
  =
  \frac 1 {\sqrt{2\pi}} \int_\R e^{- \frac 1 2 (x^2 - 2tx + t^2) + \frac 1 2 t^2} dx
  = \\ &=
  \frac {e^{t^2}} {\sqrt \pi} \int_\R e^{- {\left(\frac {x - t} {\sqrt 2} \right)}^2 + \frac 1 2 t^2} d\left( \frac {x - t} {\sqrt 2} \right)
  =
  \boxed{e^{\frac {t^2} 2}},
  \\
  \MGF'_\xi(t)
  &=
  \boxed{t e^{\frac {t^2} 2}},
  \\
  \MGF''_\xi(t)
  &=
  1 \cdot e^{\frac {t^2} 2} + t \cdot t e^{\frac {t^2} 2}
  =
  \boxed{(1 + t^2) e^{\frac {t^2} 2}}
  \\
  \Expect(\xi)
  &=
  \MGF'_\xi(0)
  =
  \boxed{0},
  \\
  \Expect(\xi^2)
  &=
  \MGF''_\xi(0)
  =
  \boxed{1}
  \\
  \Var(\xi)
  &=
  \Expect(\xi^2) - {\Expect(\xi)}^2
  =
  1 - 0
  =
  \boxed{1}.
\end{align*}
\endgroup

Тогава за оригиналната случайна величина $\eta \in \DNormal(\mu, \sigma^2)$ имаме
\begin{align*}
  \Expect(\eta) &= \Expect(\sigma \xi + \mu) = \sigma \Expect(\eta) + \mu = \boxed{\mu}, \\
  \Var(\eta) &= \Var(\sigma \xi + \mu) = \sigma^2 \Var(\xi) = \boxed{\sigma^2}.
\end{align*}

Получихме, че произволна нормална случайна величина $\eta \in \DNormal(\mu, \sigma^2)$ има очакване $\mu$ и дисперсия $\sigma^2$, които отговарят на съответните параметри. Стандартизираните нормални случайни величини тогава винаги имат стандартно нормално разпределение.

Освен това, от вида на пораждащата моментите функция на $\eta$
\begin{displaymath}
  \MGF_\eta(t)
  =
  \Expect(e^{t\eta})
  =
  \Expect(e^{t(\sigma\xi + \mu)})
  =
  \Expect(e^{(\sigma t) \xi}) e^{t\mu}
  =
  e^{t\mu} \MGF_\xi(\sigma t)
  =
  \boxed{e^{t\mu} e^{\frac {\sigma^2 t^2} 2}}
\end{displaymath}
става ясно, че сумата на две нормални случайни величини $\xi_k \in \DNormal(\mu_k, \sigma_k^2), k = 1, 2$ е отново нормална с параметри $\xi_1 + \xi_2 \in \DNormal(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$.

Ако $\xi_1, \ldots, \xi_n$ са стандартни нормални, сумата им има разпределение $\DNormal(0, n)$. За да бъде сумата стандартна нормална, стандартизираме чрез
\begin{displaymath}
  \frac 1 {\sqrt n} \sum_{k=1}^n \xi_k.
\end{displaymath}

При $n \to \infty$ това свойство се обобщава за различни по рода си разпределения, както може да бъде видяно от следните теореми

\begin{theorem}[Централна гранична теорема за еднакво разпределени случайни величини]
  Нека $\xi_1, \xi_2, \ldots$ са независими и еднакво разпределени случайни величини с крайна дисперсия. Без ограничение на общността считаме, че те са стандартизирани.

  Тогава случайната величина
  \begin{displaymath}
    \frac 1 {\sqrt n} \sum_{k=1}^n \xi_k.
  \end{displaymath}
  при $n \to \infty$ клони по вероятност към стандартно нормално разпределение.
\end{theorem}

\begin{theorem}[Централна гранична теорема с условие на Ляпунов]
  Нека $\xi_1, \xi_2, \ldots$ са независими случайни величини с крайни дисперсии. Без ограничение на общността считаме, че те са стандартизирани.
  Ако за някое $\delta > 2$ е изпълнено условието на Ляпунов,
  \begin{displaymath}
    \lim_{n \to \infty} \frac 1 {n^{\frac \delta 2}} \sum_{k=1}^n \Expect \left( {\Abs{\xi_k}}^\delta \right) = 0,
  \end{displaymath}
  тогава случайната величина
  \begin{displaymath}
    \frac 1 {\sqrt n} \sum_{k=1}^n \xi_k.
  \end{displaymath}
  при $n \to \infty$ клони по вероятност към стандартно нормално разпределение.
\end{theorem}

\subsubsection{Равномерно разпределение}

\begin{definition}
  Казваме, че случайната величина $\xi$ е \uline{равномерно разпределена} в интервала $[a, b]$ пишем $\xi \in \DUniform(a, b)$, ако плътността има вида
  \begin{displaymath}
    f_\xi(x)
    =
    \begin{cases}
      \frac 1 {b-a}, x \in [a, b]
      0, & x \not\in [a, b]
    \end{cases}
  \end{displaymath}

  Дефиницията на плътност е коректна, тъй като за $x \in [a, b]$ е в сила $f_\xi(x) = \frac 1 {b-a} > 0$ и
  \begin{displaymath}
    \int_\R f_\xi(x) dx
    =
    \int_a^b \frac 1 {b-a} dx
    =
    1.
  \end{displaymath}
\end{definition}

Равномерното разпределение има две основни приложения:
\begin{enumerate}
  \item За Монте-Карло симулации на непрекъснати разпределения, чиято функция на разпределение има проста за пресмятане обратна.
  \item За моделиране експерименти с континуум от възможни изходи, за които предполагаме, че са равновероятни. Например попадението на материална точка в даден паралелепипед.
\end{enumerate}

За пораждащата моментите функция, очакването и дисперсията на $\xi \in \DUniform(a, b)$ имаме
\begingroup
\allowdisplaybreaks
\begin{align*}
  \MGF_\xi(t)
  &=
  \Expect(e^{t\xi})
  =
  \frac 1 {b-a} \int_a^b e^{tx} dx
  =
  \boxed{\begin{cases}
    1, &t = 0 \\
    \frac {e^{tb} - e^{ta}} {t(b-a)}, &t \neq 0
  \end{cases}}
  \\
  \Expect(\xi)
  &=
  \frac 1 {b-a} \int_a^b x dx
  =
  \frac {b^2 - a^2} {2(b-a)}
  =
  \frac {(b-a)(b+a)} {2(b-a)}
  =
  \boxed{\frac {a + b} 2},
  \\
  \Expect(\xi^2)
  &=
  \frac 1 {b-a} \int_a^b x^2 dx
  =
  \frac {b^3 - a^3} {3(b-a)}
  =
  \frac {(b-a)(b^2+ba+a^2)} {3(b-a)}
  =
  \boxed{\frac {b^2+ba+a^2} 3},
  \\
  \Var(\xi)
  &=
  \Expect(\xi^2) - {\Expect(\xi)}^2
  =
  \frac {b^2+ba+a^2} 3 - {\left(\frac {a+b} 2 \right)}^2
  =
  \frac {4(b^2+ba+a^2)} {12} - \frac {3 (a^2+2ab+b^2)} {12}
  = \\ &=
  \frac {b^2-2ba+a^2} {12}
  =
  \boxed{\frac {{(b-a)}^2} {12}}.
\end{align*}
\endgroup

\subsubsection{Експоненциално разпределение}

\begin{definition}
  Казваме, че случайната величина $\xi$ има \uline{експоненциално разпределение} с интензивност $\lambda > 0$ и пишем $\xi \in \DExp(\lambda)$, ако плътността има вида
  \begin{displaymath}
    f_\xi(x) = \begin{cases}
      \lambda e^{-\lambda x}, & x \geq 0 \\
      0, &x < 0.
    \end{cases}
  \end{displaymath}

  Дефиницията на плътност е коректна, тъй като $f_\xi(x) \geq 0~\forall x \in \R$ и
  \begin{displaymath}
    \int_\R \varphi(x) dx
    =
    \int_0^\infty \lambda e^{-\lambda x} dx
    =
    -\int_0^\infty e^{-\lambda x} d(-\lambda x)
    =
    -(\lim_{x \to \infty} e^{-\lambda x} - 1)
    =
    1.
  \end{displaymath}

  Понякога се използва алтернативна параметризация, където плътността има вида
  \begin{displaymath}
    f_\xi(x) = \begin{cases}
      \frac 1 \lambda e^{-\frac x \lambda}, & x \geq 0 \\
      0, &x < 0.
    \end{cases}
  \end{displaymath}
\end{definition}

Експоненциалното разпределение моделира време на изчакване. Това включва време за чакане на градски транспорт, време до настъпване на застрахователно събитие или време за полуразпад на радиоактивно вещество. Предимство на експоненциалното разпределение за тези модели е свойството липса на памет, описано в теорема~\ref{thm:memorylessness}.

За функцията на разпределение, пораждащата моментите функция, очакването и дисперсията на $\xi \in \DExp(\lambda)$ имаме
\begingroup
\allowdisplaybreaks
\begin{align*}
  F_\xi(x)
  &=
  \int_{-\infty}^x f_\xi(y) dy
  =
  \int_0^x \lambda e^{-\lambda y} dy
  =
  -\int_0^x e^{-\lambda y} d(-\lambda y)
  =
  -(e^{-\lambda x} - 1)
  =
  \boxed{1 - e^{-\lambda x}},
  \\
  \MGF_\xi(t)
  &=
  \Expect(e^{t\xi})
  =
  \int_0^\infty e^{tx} \cdot \lambda e^{-\lambda x} dx
  =
  \frac \lambda {t-\lambda} \int_0^\infty e^{x(t-\lambda)} d[x(t-\lambda)]
  = \\ &=
  \frac \lambda {t-\lambda} (\lim_{x \to \infty} e^{x(t-\lambda)} - 1)
  =
  \frac \lambda {\lambda-t}
  =
  {\left(\frac {\lambda-t} \lambda \right)}^{-1}
  =
  \boxed{{\left(1 - \frac t \lambda \right)}^{-1}, t < \lambda},
  \\
  \MGF'_\xi(t)
  &=
  \boxed{\frac 1 \lambda {\left(1 - \frac t \lambda \right)}^{-2}, t < \lambda},
  \\
  \MGF''_\xi(t)
  &=
  \boxed{\frac 2 {\lambda^2} {\left(1 - \frac t \lambda \right)}^{-3}, t < \lambda},
  \\
  \Expect(\xi)
  &=
  \MGF'_\xi(0)
  =
  \boxed{\frac 1 \lambda},
  \\
  \Expect(\xi^2)
  &=
  \MGF''_\xi(0)
  =
  \boxed{\frac 2 {\lambda^2}},
  \\
  \Var(\xi)
  &=
  \Expect(\xi^2) - {\Expect(\xi)}^2
  =
  \frac 2 {\lambda^2} - \frac 1 {\lambda^2}
  =
  \frac 1 {\lambda^2}.
\end{align*}
\endgroup

\begin{theorem}[Липса на памет]\label{thm:memorylessness}
  За $\xi \in \DExp(\lambda)$ и $x, y > 0$ е изпълнено
  \begin{displaymath}
    \Prob(\xi > x + y \mid \xi > x) = \Prob(\xi > y).
  \end{displaymath}
\end{theorem}
\begin{proof}
  \begin{multline*}
    \Prob(\xi > x + y \mid \xi > x)
    =
    \frac {\Prob(\xi > x + y, \xi > x)} {\Prob(\xi > x)}
    =
    \frac {\Prob(\xi > x + y)} {\Prob(\xi > x)}
    =
    \frac {1-F_\xi(x+y)} {1-F_\xi(x)}
    = \\ =
    \frac {e^{-\lambda(x+y)}} {e^{-\lambda x}}
    =
    e^{-\lambda y}
    =
    1-F_\xi(y)
    =
    \Prob(\xi > y).
  \end{multline*}
\end{proof}

\subsubsection{Гама разпределение}

\begin{definition}
  Казваме, че случайната величина $\xi$ има \uline{гама разпределение} с мащаб $\alpha > 0$ и интензивност $\beta > 0$ и пишем $\xi \in \DGamma(\alpha, \beta)$, ако плътността има вида
  \begin{displaymath}
    f_\xi(x) = \frac {\beta^\alpha x^{\alpha-1} e^{-\beta x}} {\Gamma(\alpha)},
  \end{displaymath}
  където $\Gamma(x)$ е $\Gamma$-функцията на Ойлер.

  Дефиницията на плътност е коректна, тъй като $f_\xi(x) \geq 0~\forall x \in \R$ и
  \begin{displaymath}
    \frac 1 {\Gamma(\alpha)} \int_\R {\beta^\alpha x^{\alpha-1} e^{-\beta x}} dx
    =
    \frac 1 {\Gamma(\alpha)} \int_\R {{(\beta x)}^{\alpha-1} e^{-\beta x}} d(\beta x)
    =
    \frac {\Gamma(\alpha)} {\Gamma(\alpha)}
    =
    1.
  \end{displaymath}

  Понякога се използва алтернативна параметризация с $k = \alpha$ и $\theta = \beta^{-1}$, където плътността има вида
  \begin{displaymath}
    f_\xi(x) = \frac {\theta^{-k} x^{k-1} e^{-\frac x \theta}} {\Gamma(k)}.
  \end{displaymath}
\end{definition}

Гама разпределението обобщава други често срещани разпределения като $\DExp$ и $\DChiSq$. Като такова то наследява и разширява техни приложения, например за моделиране на време между $n > 1$ последователни нервни импулса, но гама разпределението има и самостоятелни приложения, например за статистически анализ на асиметрично-разпределени данни.

За пораждащата моментите функция, очакването и дисперсията на $\xi \in \DGamma(\alpha, \beta)$ имаме
\begingroup
\allowdisplaybreaks
\begin{align*}
  \MGF_\xi(t)
  &=
  \Expect(e^{t\xi})
  =
  \int_\R e^{tx} \cdot \frac {\beta^\alpha x^{\alpha-1} e^{-\beta x}} {\Gamma(\alpha)} dx
  =
  \frac {\beta^\alpha} {\Gamma(\alpha)} \int_\R x^{\alpha-1} e^{-x(\beta-t)} dx
  = \\ &=
  \frac {\beta^\alpha} {(\beta-t) \cdot \Gamma(\alpha)} \int_\R \frac {{[(\beta-t)x]}^{\alpha-1}} {{(\beta-t)}^{\alpha-1}} e^{-(\beta-t)x} d[(\beta-t)x]
  = \\ &=
  {\left(\frac \beta {\beta-t} \right)}^\alpha \frac 1 {\Gamma(\alpha)} \int_\R {[(\beta-t)x]}^{\alpha-1} e^{-(\beta-t)x} d[(\beta-t)x]
  = \\ &=
  {\left(\frac \beta {\beta-t} \right)}^\alpha \frac {\Gamma(\alpha)} {\Gamma(\alpha)}
  =
  {\left(\frac {\beta-t} \beta \right)}^{-\alpha}
  =
  \boxed{{\left(1 - \frac t \beta \right)}^{-\alpha}, t < \beta},
  \\
  \MGF'_\xi(t)
  &=
  \boxed{\frac \alpha \beta {\left(1 - \frac t \beta \right)}^{-\alpha-1}, t < \beta},
  \\
  \MGF''_\xi(t)
  &=
  \boxed{\frac {\alpha(\alpha+1)} {\beta^2} {\left(1 - \frac t \beta \right)}^{-\alpha-2}, t < \beta},
  \\
  \Expect(\xi)
  &=
  \MGF'_\xi(0)
  =
  \boxed{\frac \alpha \beta},
  \\
  \Expect(\xi^2)
  &=
  \MGF''_\xi(0)
  =
  \boxed{\frac {\alpha(\alpha+1)} {\beta^2}},
  \\
  \Var(\xi)
  &=
  \Expect(\xi^2) - {\Expect(\xi)}^2
  =
  \frac {\alpha(\alpha+1)} {\beta^2} - \frac {\alpha^2} {\beta^2}
  =
  \frac \alpha {\beta^2}.
\end{align*}
\endgroup

\printbibliography

\end{document}
